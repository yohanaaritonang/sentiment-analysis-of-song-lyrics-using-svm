{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26.9 ms\n",
      "Wall time: 18 ms\n"
     ]
    }
   ],
   "source": [
    "%time train_data = pd.read_csv(\"Train.csv\", delimiter=',', index_col =0)\n",
    "%time test_data = pd.read_csv(\"Test.csv\", delimiter=',', index_col =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist's Name</th>\n",
       "      <th>Duration of Music (seconds)</th>\n",
       "      <th>Category</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SongID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>A Place Nearby</td>\n",
       "      <td>Lene Marlin</td>\n",
       "      <td>252</td>\n",
       "      <td>sad</td>\n",
       "      <td>I entered the room Sat by your bed all through...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Flying</td>\n",
       "      <td>Anathema</td>\n",
       "      <td>358</td>\n",
       "      <td>sad</td>\n",
       "      <td>Started a search to no avail a light that shin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Innocent</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>302</td>\n",
       "      <td>sad</td>\n",
       "      <td>Guess you really did it this time Left yoursel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Handle This</td>\n",
       "      <td>SUM 41</td>\n",
       "      <td>218</td>\n",
       "      <td>angry</td>\n",
       "      <td>You said it once before you don't do those thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>I'Ve Never Been To Me</td>\n",
       "      <td>Charlene</td>\n",
       "      <td>229</td>\n",
       "      <td>relaxed</td>\n",
       "      <td>Hey lady, you, lady, cursing at your life You'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Song Name Artist's Name  Duration of Music (seconds)  \\\n",
       "SongID                                                                     \n",
       "204            A Place Nearby   Lene Marlin                          252   \n",
       "250                    Flying      Anathema                          358   \n",
       "287                  Innocent  Taylor Swift                          302   \n",
       "48                Handle This        SUM 41                          218   \n",
       "352     I'Ve Never Been To Me      Charlene                          229   \n",
       "\n",
       "       Category                                             Lyrics  \n",
       "SongID                                                              \n",
       "204         sad  I entered the room Sat by your bed all through...  \n",
       "250         sad  Started a search to no avail a light that shin...  \n",
       "287         sad  Guess you really did it this time Left yoursel...  \n",
       "48        angry  You said it once before you don't do those thi...  \n",
       "352     relaxed  Hey lady, you, lady, cursing at your life You'...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist's Name</th>\n",
       "      <th>Duration of Music (seconds)</th>\n",
       "      <th>Category</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SongID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Time for You to Go</td>\n",
       "      <td>Sum 41</td>\n",
       "      <td>182</td>\n",
       "      <td>angry</td>\n",
       "      <td>I'm going in alone, did my time and now I'm do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>To Blossom Blue</td>\n",
       "      <td>Lake Of Tears</td>\n",
       "      <td>495</td>\n",
       "      <td>sad</td>\n",
       "      <td>I'm bleeding ya bleeding in ways of the fire b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>You Give Me Something</td>\n",
       "      <td>James Morrison</td>\n",
       "      <td>213</td>\n",
       "      <td>sad</td>\n",
       "      <td>You want to stay with me in the morning You on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93 Million Miles</td>\n",
       "      <td>Jason Mraz</td>\n",
       "      <td>218</td>\n",
       "      <td>happy</td>\n",
       "      <td>93 million miles from the Sun,  people get rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>What He Wrote</td>\n",
       "      <td>Laura Marling</td>\n",
       "      <td>249</td>\n",
       "      <td>sad</td>\n",
       "      <td>Forgive me, Hera, I cannot stay He cut out my ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Song Name   Artist's Name  Duration of Music (seconds)  \\\n",
       "SongID                                                                       \n",
       "57         Time for You to Go          Sum 41                          182   \n",
       "78            To Blossom Blue   Lake Of Tears                          495   \n",
       "95      You Give Me Something  James Morrison                          213   \n",
       "4            93 Million Miles      Jason Mraz                          218   \n",
       "86              What He Wrote   Laura Marling                          249   \n",
       "\n",
       "       Category                                             Lyrics  \n",
       "SongID                                                              \n",
       "57        angry  I'm going in alone, did my time and now I'm do...  \n",
       "78          sad  I'm bleeding ya bleeding in ways of the fire b...  \n",
       "95          sad  You want to stay with me in the morning You on...  \n",
       "4         happy  93 million miles from the Sun,  people get rea...  \n",
       "86          sad  Forgive me, Hera, I cannot stay He cut out my ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting the Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist's Name</th>\n",
       "      <th>Duration of Music (seconds)</th>\n",
       "      <th>Category</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SongID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Song Name  Artist's Name  Duration of Music (seconds)  Category  \\\n",
       "SongID                                                                    \n",
       "1           False          False                        False     False   \n",
       "2           False          False                        False     False   \n",
       "3           False          False                        False     False   \n",
       "4           False          False                        False     False   \n",
       "5           False          False                        False     False   \n",
       "...           ...            ...                          ...       ...   \n",
       "396         False          False                        False     False   \n",
       "397         False          False                        False     False   \n",
       "398         False          False                        False     False   \n",
       "399         False          False                        False     False   \n",
       "400         False          False                        False     False   \n",
       "\n",
       "        Lyrics  \n",
       "SongID          \n",
       "1        False  \n",
       "2        False  \n",
       "3        False  \n",
       "4        False  \n",
       "5        False  \n",
       "...        ...  \n",
       "396      False  \n",
       "397      False  \n",
       "398      False  \n",
       "399      False  \n",
       "400      False  \n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist's Name</th>\n",
       "      <th>Duration of Music (seconds)</th>\n",
       "      <th>Category</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SongID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Song Name  Artist's Name  Duration of Music (seconds)  Category  \\\n",
       "SongID                                                                    \n",
       "1           False          False                        False     False   \n",
       "2           False          False                        False     False   \n",
       "3           False          False                        False     False   \n",
       "4           False          False                        False     False   \n",
       "5           False          False                        False     False   \n",
       "...           ...            ...                          ...       ...   \n",
       "97          False          False                        False     False   \n",
       "98          False          False                        False     False   \n",
       "99          False          False                        False     False   \n",
       "100         False          False                        False     False   \n",
       "101         False          False                        False     False   \n",
       "\n",
       "        Lyrics  \n",
       "SongID          \n",
       "1        False  \n",
       "2        False  \n",
       "3        False  \n",
       "4        False  \n",
       "5        False  \n",
       "...        ...  \n",
       "97       False  \n",
       "98       False  \n",
       "99       False  \n",
       "100      False  \n",
       "101      False  \n",
       "\n",
       "[378 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing the Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Song Name                      0\n",
       "Artist's Name                  0\n",
       "Duration of Music (seconds)    0\n",
       "Category                       0\n",
       "Lyrics                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Song Name                      0\n",
       "Artist's Name                  0\n",
       "Duration of Music (seconds)    0\n",
       "Category                       0\n",
       "Lyrics                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column does not contain Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Case Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Lyrics'] = train_data['Lyrics'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SongID\n",
      "1      another day wasted out of time i can't get out...\n",
      "2      crawl from the wreckage one more time horrific...\n",
      "3      don't wanna be an american idiot.  don't want ...\n",
      "4      the more of you that i inspect the more of me ...\n",
      "5      the prophets of god have left you solaced inde...\n",
      "                             ...                        \n",
      "396    over the rainbow what a wonderful world \"orion...\n",
      "397    the sunshineâs come, the flowers dance along...\n",
      "398    this stone that i have swallowed isn't goin do...\n",
      "399    love is like an aero plane you jump and then y...\n",
      "400    wise men say wise men say wise men say the bad...\n",
      "Name: Lyrics, Length: 400, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_Lyrics = train_data.iloc[:400]\n",
    "print(train_Lyrics['Lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Lyrics'] = test_data['Lyrics'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SongID\n",
      "1      sometimes you just feel tired, feel weak when ...\n",
      "2      too late for the other side caught in a change...\n",
      "3      cast your eyes into the distance try to focus ...\n",
      "4      look like ass, smell like shit why are you suc...\n",
      "5      you find me offensive i find you offensive for...\n",
      "                             ...                        \n",
      "97     the bluest skies don't seem so blue and the st...\n",
      "98     you are my sunshine, my only sunshine you make...\n",
      "99     see the pyramids along the nile watch the sunr...\n",
      "100    see the pyramids along the nile watch the sun ...\n",
      "101    staring at the moon so blue turning all my tho...\n",
      "Name: Lyrics, Length: 378, dtype: object\n"
     ]
    }
   ],
   "source": [
    "test_Lyrics = test_data.iloc[:400]\n",
    "print(test_Lyrics['Lyrics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\ITD-\n",
      "[nltk_data]     STU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegexpTokenizer(pattern=SongID\n",
      "1      another day wasted out of time i can't get out...\n",
      "2      crawl from the wreckage one more time horrific...\n",
      "3      don't wanna be an american idiot.  don't want ...\n",
      "4      the more of you that i inspect the more of me ...\n",
      "5      the prophets of god have left you solaced inde...\n",
      "                             ...                        \n",
      "396    over the rainbow what a wonderful world \"orion...\n",
      "397    the sunshineâs come, the flowers dance along...\n",
      "398    this stone that i have swallowed isn't goin do...\n",
      "399    love is like an aero plane you jump and then y...\n",
      "400    wise men say wise men say wise men say the bad...\n",
      "Name: Lyrics, Length: 400, dtype: object, gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>)\n"
     ]
    }
   ],
   "source": [
    "Regtokenizer = RegexpTokenizer(train_Lyrics['Lyrics'])\n",
    "print(Regtokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegexpTokenizer(pattern=SongID\n",
      "1      sometimes you just feel tired, feel weak when ...\n",
      "2      too late for the other side caught in a change...\n",
      "3      cast your eyes into the distance try to focus ...\n",
      "4      look like ass, smell like shit why are you suc...\n",
      "5      you find me offensive i find you offensive for...\n",
      "                             ...                        \n",
      "97     the bluest skies don't seem so blue and the st...\n",
      "98     you are my sunshine, my only sunshine you make...\n",
      "99     see the pyramids along the nile watch the sunr...\n",
      "100    see the pyramids along the nile watch the sun ...\n",
      "101    staring at the moon so blue turning all my tho...\n",
      "Name: Lyrics, Length: 378, dtype: object, gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>)\n"
     ]
    }
   ],
   "source": [
    "Regtokenizer = RegexpTokenizer(test_Lyrics['Lyrics'])\n",
    "print(Regtokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing Result : \n",
      "\n",
      "SongID\n",
      "1      [another, day, wasted, out, of, time, cant, ge...\n",
      "2      [crawl, from, the, wreckage, one, more, time, ...\n",
      "3      [dont, wan, na, be, an, american, idiot, dont,...\n",
      "4      [the, more, of, you, that, inspect, the, more,...\n",
      "5      [the, prophets, of, god, have, left, you, sola...\n",
      "                             ...                        \n",
      "396    [over, the, rainbow, what, wonderful, world, o...\n",
      "397    [the, sunshineâ, come, the, flowers, dance, ...\n",
      "398    [this, stone, that, have, swallowed, isnt, goi...\n",
      "399    [love, is, like, an, aero, plane, you, jump, a...\n",
      "400    [wise, men, say, wise, men, say, wise, men, sa...\n",
      "Name: Lyrics_tokens, Length: 400, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "import re\n",
    "#remove number\n",
    "def remove_number(text):\n",
    "    return  re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "train_data['Lyrics'] = train_data['Lyrics'].apply(remove_number)\n",
    "\n",
    "#remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "\n",
    "train_data['Lyrics'] = train_data['Lyrics'].apply(remove_punctuation)\n",
    "\n",
    "#remove whitespace leading & trailing\n",
    "def remove_whitespace_LT(text):\n",
    "    return text.strip()\n",
    "\n",
    "train_data['Lyrics'] = train_data['Lyrics'].apply(remove_whitespace_LT)\n",
    "\n",
    "#remove multiple whitespace into single whitespace\n",
    "def remove_whitespace_multiple(text):\n",
    "    return re.sub('\\s+',' ',text)\n",
    "\n",
    "train_data['Lyrics'] = train_data['Lyrics'].apply(remove_whitespace_multiple)\n",
    "\n",
    "# remove single char\n",
    "def remove_singl_char(text):\n",
    "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "\n",
    "train_data['Lyrics'] = train_data['Lyrics'].apply(remove_singl_char)\n",
    "\n",
    "# NLTK word tokenize \n",
    "def word_tokenize_wrapper(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "train_data['Lyrics_tokens']= train_data['Lyrics'].apply(word_tokenize_wrapper)\n",
    "\n",
    "print('Tokenizing Result : \\n') \n",
    "print(train_data['Lyrics_tokens'])\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist's Name</th>\n",
       "      <th>Duration of Music (seconds)</th>\n",
       "      <th>Category</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Lyrics_tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SongID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>Milk And Toast And Honey</td>\n",
       "      <td>Roxette</td>\n",
       "      <td>247</td>\n",
       "      <td>relaxed</td>\n",
       "      <td>milk and toast and honey make it sunny on  rai...</td>\n",
       "      <td>[milk, and, toast, and, honey, make, it, sunny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Lollipop</td>\n",
       "      <td>Mika</td>\n",
       "      <td>189</td>\n",
       "      <td>happy</td>\n",
       "      <td>said sucking too hard on your lollipop oh lov...</td>\n",
       "      <td>[said, sucking, too, hard, on, your, lollipop,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Another Time Around</td>\n",
       "      <td>Sum 41</td>\n",
       "      <td>416</td>\n",
       "      <td>angry</td>\n",
       "      <td>in my years ive seen all sounds of misconcepti...</td>\n",
       "      <td>[in, my, years, ive, seen, all, sounds, of, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Bruises</td>\n",
       "      <td>Chairlift</td>\n",
       "      <td>241</td>\n",
       "      <td>happy</td>\n",
       "      <td>tried to do handstands for you  tried to do h...</td>\n",
       "      <td>[tried, to, do, handstands, for, you, tried, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Out From Under</td>\n",
       "      <td>Britney Spears</td>\n",
       "      <td>236</td>\n",
       "      <td>relaxed</td>\n",
       "      <td>breathe you out breathe you in you keep coming...</td>\n",
       "      <td>[breathe, you, out, breathe, you, in, you, kee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Song Name   Artist's Name  Duration of Music (seconds)  \\\n",
       "SongID                                                                          \n",
       "383     Milk And Toast And Honey         Roxette                          247   \n",
       "189                     Lollipop            Mika                          189   \n",
       "6            Another Time Around          Sum 41                          416   \n",
       "103                      Bruises       Chairlift                          241   \n",
       "395               Out From Under  Britney Spears                          236   \n",
       "\n",
       "       Category                                             Lyrics  \\\n",
       "SongID                                                               \n",
       "383     relaxed  milk and toast and honey make it sunny on  rai...   \n",
       "189       happy   said sucking too hard on your lollipop oh lov...   \n",
       "6         angry  in my years ive seen all sounds of misconcepti...   \n",
       "103       happy   tried to do handstands for you  tried to do h...   \n",
       "395     relaxed  breathe you out breathe you in you keep coming...   \n",
       "\n",
       "                                            Lyrics_tokens  \n",
       "SongID                                                     \n",
       "383     [milk, and, toast, and, honey, make, it, sunny...  \n",
       "189     [said, sucking, too, hard, on, your, lollipop,...  \n",
       "6       [in, my, years, ive, seen, all, sounds, of, mi...  \n",
       "103     [tried, to, do, handstands, for, you, tried, t...  \n",
       "395     [breathe, you, out, breathe, you, in, you, kee...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing Result : \n",
      "\n",
      "SongID\n",
      "1      [sometimes, you, just, feel, tired, feel, weak...\n",
      "2      [too, late, for, the, other, side, caught, in,...\n",
      "3      [cast, your, eyes, into, the, distance, try, t...\n",
      "4      [look, like, ass, smell, like, shit, why, are,...\n",
      "5      [you, find, me, offensive, find, you, offensiv...\n",
      "                             ...                        \n",
      "97     [the, bluest, skies, dont, seem, so, blue, and...\n",
      "98     [you, are, my, sunshine, my, only, sunshine, y...\n",
      "99     [see, the, pyramids, along, the, nile, watch, ...\n",
      "100    [see, the, pyramids, along, the, nile, watch, ...\n",
      "101    [staring, at, the, moon, so, blue, turning, al...\n",
      "Name: Lyrics_tokens, Length: 378, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "import re\n",
    "#remove number\n",
    "def remove_number(text):\n",
    "    return  re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "test_data['Lyrics'] = test_data['Lyrics'].apply(remove_number)\n",
    "\n",
    "#remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "\n",
    "test_data['Lyrics'] = test_data['Lyrics'].apply(remove_punctuation)\n",
    "\n",
    "#remove whitespace leading & trailing\n",
    "def remove_whitespace_LT(text):\n",
    "    return text.strip()\n",
    "\n",
    "test_data['Lyrics'] = test_data['Lyrics'].apply(remove_whitespace_LT)\n",
    "\n",
    "#remove multiple whitespace into single whitespace\n",
    "def remove_whitespace_multiple(text):\n",
    "    return re.sub('\\s+',' ',text)\n",
    "\n",
    "test_data['Lyrics'] = test_data['Lyrics'].apply(remove_whitespace_multiple)\n",
    "\n",
    "# remove single char\n",
    "def remove_singl_char(text):\n",
    "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "\n",
    "test_data['Lyrics'] = test_data['Lyrics'].apply(remove_singl_char)\n",
    "\n",
    "# NLTK word tokenize \n",
    "def word_tokenize_wrapper(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "test_data['Lyrics_tokens']= test_data['Lyrics'].apply(word_tokenize_wrapper)\n",
    "\n",
    "print('Tokenizing Result : \\n') \n",
    "print(test_data['Lyrics_tokens'])\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist's Name</th>\n",
       "      <th>Duration of Music (seconds)</th>\n",
       "      <th>Category</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Lyrics_tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SongID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>The Girl I Knew Somewhere</td>\n",
       "      <td>The Monkees</td>\n",
       "      <td>152</td>\n",
       "      <td>happy</td>\n",
       "      <td>ï»¿you tell me that youve never been this way ...</td>\n",
       "      <td>[ï, », ¿you, tell, me, that, youve, never, bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Never Know</td>\n",
       "      <td>Jack Johnson</td>\n",
       "      <td>212</td>\n",
       "      <td>happy</td>\n",
       "      <td>hear this old story before if people keep app...</td>\n",
       "      <td>[hear, this, old, story, before, if, people, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Stationary Stationery</td>\n",
       "      <td>Anberlin</td>\n",
       "      <td>181</td>\n",
       "      <td>angry</td>\n",
       "      <td>do they not have pen or paper where you are be...</td>\n",
       "      <td>[do, they, not, have, pen, or, paper, where, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Skinny Little Bitch</td>\n",
       "      <td>Hole</td>\n",
       "      <td>194</td>\n",
       "      <td>angry</td>\n",
       "      <td>in your desperation to disappear and you would...</td>\n",
       "      <td>[in, your, desperation, to, disappear, and, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 Years Time</td>\n",
       "      <td>Noah And The Whale</td>\n",
       "      <td>216</td>\n",
       "      <td>happy</td>\n",
       "      <td>oh well in years time we could be walking arou...</td>\n",
       "      <td>[oh, well, in, years, time, we, could, be, wal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Song Name       Artist's Name  \\\n",
       "SongID                                                  \n",
       "80      The Girl I Knew Somewhere         The Monkees   \n",
       "34                     Never Know        Jack Johnson   \n",
       "33          Stationary Stationery            Anberlin   \n",
       "19            Skinny Little Bitch                Hole   \n",
       "3                    5 Years Time  Noah And The Whale   \n",
       "\n",
       "        Duration of Music (seconds) Category  \\\n",
       "SongID                                         \n",
       "80                              152    happy   \n",
       "34                              212    happy   \n",
       "33                              181    angry   \n",
       "19                              194    angry   \n",
       "3                               216    happy   \n",
       "\n",
       "                                                   Lyrics  \\\n",
       "SongID                                                      \n",
       "80      ï»¿you tell me that youve never been this way ...   \n",
       "34       hear this old story before if people keep app...   \n",
       "33      do they not have pen or paper where you are be...   \n",
       "19      in your desperation to disappear and you would...   \n",
       "3       oh well in years time we could be walking arou...   \n",
       "\n",
       "                                            Lyrics_tokens  \n",
       "SongID                                                     \n",
       "80      [ï, », ¿you, tell, me, that, youve, never, bee...  \n",
       "34      [hear, this, old, story, before, if, people, k...  \n",
       "33      [do, they, not, have, pen, or, paper, where, y...  \n",
       "19      [in, your, desperation, to, disappear, and, yo...  \n",
       "3       [oh, well, in, years, time, we, could, be, wal...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\ITD-\n",
      "[nltk_data]     STU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print (stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SongID\n",
      "1      [another, day, wasted, time, cant, get, altere...\n",
      "2      [crawl, wreckage, one, time, horrific, memory,...\n",
      "3      [dont, wan, na, american, idiot, dont, want, n...\n",
      "4      [inspect, see, reflect, try, read, lips, mask,...\n",
      "5      [prophets, god, left, solaced, indeed, zombie,...\n",
      "                             ...                        \n",
      "396    [rainbow, wonderful, world, orion, somewhere, ...\n",
      "397    [sunshineâ, come, flowers, dance, along, riv...\n",
      "398    [stone, swallowed, isnt, goin, well, road, fol...\n",
      "399    [love, like, aero, plane, jump, pray, lucky, o...\n",
      "400    [wise, men, say, wise, men, say, wise, men, sa...\n",
      "Name: Lyrics_tokens_SW, Length: 400, dtype: object\n"
     ]
    }
   ],
   "source": [
    "list_stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def stopwords_removal(words):\n",
    "    return [word for word in words if word not in list_stopwords]\n",
    "train_data['Lyrics_tokens_SW'] = train_data['Lyrics_tokens'].apply(stopwords_removal) \n",
    "print(train_data['Lyrics_tokens_SW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist's Name</th>\n",
       "      <th>Duration of Music (seconds)</th>\n",
       "      <th>Category</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Lyrics_tokens</th>\n",
       "      <th>Lyrics_tokens_SW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SongID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>I Could Be The One ( Lp Version )</td>\n",
       "      <td>Donna Lewis</td>\n",
       "      <td>230</td>\n",
       "      <td>happy</td>\n",
       "      <td>could be your sea of sand  could be your warm...</td>\n",
       "      <td>[could, be, your, sea, of, sand, could, be, yo...</td>\n",
       "      <td>[could, sea, sand, could, warmth, desire, coul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Chloe (You're The One I Want)</td>\n",
       "      <td>Emblem3</td>\n",
       "      <td>592</td>\n",
       "      <td>happy</td>\n",
       "      <td>chloe  know your sister turns everyone on but ...</td>\n",
       "      <td>[chloe, know, your, sister, turns, everyone, o...</td>\n",
       "      <td>[chloe, know, sister, turns, everyone, youre, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Dreaming My Dreams With You</td>\n",
       "      <td>Alison Krauss</td>\n",
       "      <td>268</td>\n",
       "      <td>relaxed</td>\n",
       "      <td>dreaming my dreams with youalison krauss  hope...</td>\n",
       "      <td>[dreaming, my, dreams, with, youalison, krauss...</td>\n",
       "      <td>[dreaming, dreams, youalison, krauss, hope, wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Get Lucky</td>\n",
       "      <td>dragonette</td>\n",
       "      <td>186</td>\n",
       "      <td>happy</td>\n",
       "      <td>sometimes the sun shines on us sometimes the r...</td>\n",
       "      <td>[sometimes, the, sun, shines, on, us, sometime...</td>\n",
       "      <td>[sometimes, sun, shines, us, sometimes, rain, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Don'T Stop Movin'</td>\n",
       "      <td>S Club 7</td>\n",
       "      <td>237</td>\n",
       "      <td>happy</td>\n",
       "      <td>djs got the party started theres no end in sig...</td>\n",
       "      <td>[djs, got, the, party, started, theres, no, en...</td>\n",
       "      <td>[djs, got, party, started, theres, end, sight,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Song Name  Artist's Name  \\\n",
       "SongID                                                     \n",
       "163     I Could Be The One ( Lp Version )    Donna Lewis   \n",
       "110         Chloe (You're The One I Want)        Emblem3   \n",
       "311           Dreaming My Dreams With You  Alison Krauss   \n",
       "144                             Get Lucky     dragonette   \n",
       "127                     Don'T Stop Movin'       S Club 7   \n",
       "\n",
       "        Duration of Music (seconds) Category  \\\n",
       "SongID                                         \n",
       "163                             230    happy   \n",
       "110                             592    happy   \n",
       "311                             268  relaxed   \n",
       "144                             186    happy   \n",
       "127                             237    happy   \n",
       "\n",
       "                                                   Lyrics  \\\n",
       "SongID                                                      \n",
       "163      could be your sea of sand  could be your warm...   \n",
       "110     chloe  know your sister turns everyone on but ...   \n",
       "311     dreaming my dreams with youalison krauss  hope...   \n",
       "144     sometimes the sun shines on us sometimes the r...   \n",
       "127     djs got the party started theres no end in sig...   \n",
       "\n",
       "                                            Lyrics_tokens  \\\n",
       "SongID                                                      \n",
       "163     [could, be, your, sea, of, sand, could, be, yo...   \n",
       "110     [chloe, know, your, sister, turns, everyone, o...   \n",
       "311     [dreaming, my, dreams, with, youalison, krauss...   \n",
       "144     [sometimes, the, sun, shines, on, us, sometime...   \n",
       "127     [djs, got, the, party, started, theres, no, en...   \n",
       "\n",
       "                                         Lyrics_tokens_SW  \n",
       "SongID                                                     \n",
       "163     [could, sea, sand, could, warmth, desire, coul...  \n",
       "110     [chloe, know, sister, turns, everyone, youre, ...  \n",
       "311     [dreaming, dreams, youalison, krauss, hope, wo...  \n",
       "144     [sometimes, sun, shines, us, sometimes, rain, ...  \n",
       "127     [djs, got, party, started, theres, end, sight,...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SongID\n",
      "1      [sometimes, feel, tired, feel, weak, feel, wea...\n",
      "2      [late, side, caught, change, life, late, side,...\n",
      "3      [cast, eyes, distance, try, focus, find, spiri...\n",
      "4      [look, like, ass, smell, like, shit, dick, wal...\n",
      "5      [find, offensive, find, offensive, finding, of...\n",
      "                             ...                        \n",
      "97     [bluest, skies, dont, seem, blue, stars, seem,...\n",
      "98     [sunshine, sunshine, make, happy, skies, gray,...\n",
      "99     [see, pyramids, along, nile, watch, sunrise, t...\n",
      "100    [see, pyramids, along, nile, watch, sun, rise,...\n",
      "101    [staring, moon, blue, turning, thoughts, witho...\n",
      "Name: Lyrics_tokens_SW, Length: 378, dtype: object\n"
     ]
    }
   ],
   "source": [
    "list_stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def stopwords_removal(words):\n",
    "    return [word for word in words if word not in list_stopwords]\n",
    "test_data['Lyrics_tokens_SW'] = test_data['Lyrics_tokens'].apply(stopwords_removal) \n",
    "print(test_data['Lyrics_tokens_SW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist's Name</th>\n",
       "      <th>Duration of Music (seconds)</th>\n",
       "      <th>Category</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Lyrics_tokens</th>\n",
       "      <th>Lyrics_tokens_SW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SongID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A N I C</td>\n",
       "      <td>Sum 41</td>\n",
       "      <td>41</td>\n",
       "      <td>angry</td>\n",
       "      <td>look like ass smell like shit why are you such...</td>\n",
       "      <td>[look, like, ass, smell, like, shit, why, are,...</td>\n",
       "      <td>[look, like, ass, smell, like, shit, dick, wal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Like A Song</td>\n",
       "      <td>Lenka</td>\n",
       "      <td>204</td>\n",
       "      <td>sad</td>\n",
       "      <td>cant forget you when youre gone your like  so...</td>\n",
       "      <td>[cant, forget, you, when, youre, gone, your, l...</td>\n",
       "      <td>[cant, forget, youre, gone, like, song, goes, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Say Hey (I Love You)</td>\n",
       "      <td>Michael Franti &amp; Spearhead</td>\n",
       "      <td>236</td>\n",
       "      <td>happy</td>\n",
       "      <td>this one goes out to you and yours worldwide  ...</td>\n",
       "      <td>[this, one, goes, out, to, you, and, yours, wo...</td>\n",
       "      <td>[one, goes, worldwide, say, hey, ill, gone, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>And Then You</td>\n",
       "      <td>Greg Laswell</td>\n",
       "      <td>212</td>\n",
       "      <td>happy</td>\n",
       "      <td>how my thoughts they spin me round how my thou...</td>\n",
       "      <td>[how, my, thoughts, they, spin, me, round, how...</td>\n",
       "      <td>[thoughts, spin, round, thoughts, let, thought...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sermon</td>\n",
       "      <td>Drowning Pool</td>\n",
       "      <td>259</td>\n",
       "      <td>angry</td>\n",
       "      <td>where was god when  needed  friend and where w...</td>\n",
       "      <td>[where, was, god, when, needed, friend, and, w...</td>\n",
       "      <td>[god, needed, friend, god, came, end, god, los...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Song Name               Artist's Name  \\\n",
       "SongID                                                     \n",
       "4                    A N I C                      Sum 41   \n",
       "1                Like A Song                       Lenka   \n",
       "54      Say Hey (I Love You)  Michael Franti & Spearhead   \n",
       "10              And Then You                Greg Laswell   \n",
       "15                    Sermon               Drowning Pool   \n",
       "\n",
       "        Duration of Music (seconds) Category  \\\n",
       "SongID                                         \n",
       "4                                41    angry   \n",
       "1                               204      sad   \n",
       "54                              236    happy   \n",
       "10                              212    happy   \n",
       "15                              259    angry   \n",
       "\n",
       "                                                   Lyrics  \\\n",
       "SongID                                                      \n",
       "4       look like ass smell like shit why are you such...   \n",
       "1        cant forget you when youre gone your like  so...   \n",
       "54      this one goes out to you and yours worldwide  ...   \n",
       "10      how my thoughts they spin me round how my thou...   \n",
       "15      where was god when  needed  friend and where w...   \n",
       "\n",
       "                                            Lyrics_tokens  \\\n",
       "SongID                                                      \n",
       "4       [look, like, ass, smell, like, shit, why, are,...   \n",
       "1       [cant, forget, you, when, youre, gone, your, l...   \n",
       "54      [this, one, goes, out, to, you, and, yours, wo...   \n",
       "10      [how, my, thoughts, they, spin, me, round, how...   \n",
       "15      [where, was, god, when, needed, friend, and, w...   \n",
       "\n",
       "                                         Lyrics_tokens_SW  \n",
       "SongID                                                     \n",
       "4       [look, like, ass, smell, like, shit, dick, wal...  \n",
       "1       [cant, forget, youre, gone, like, song, goes, ...  \n",
       "54      [one, goes, worldwide, say, hey, ill, gone, to...  \n",
       "10      [thoughts, spin, round, thoughts, let, thought...  \n",
       "15      [god, needed, friend, god, came, end, god, los...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer, LancasterStemmer, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming in train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['another', 'day', 'wasted', 'out', 'of', 'time', 'cant', 'get', 'out', 'of', 'this', 'altered', 'state', 'of', 'mind', 'im', 'going', 'overboard', 'my', 'conscience', 'meets', 'decline', 'into', 'reality', 'know', 'this', 'cant', 'be', 'fine', 'cause', 'im', 'all', 'messed', 'up', 'making', 'prefect', 'nonsense', 'drowning', 'in', 'my', 'doubt', 'too', 'well', 'cause', 'im', 'all', 'messed', 'up', 'going', 'nowhere', 'fast', 'but', 'circles', 'in', 'my', 'mind', 'so', 'blind', 'who', 'are', 'these', 'voices', 'in', 'my', 'head', 'cant', 'go', 'on', 'like', 'this', 'living', 'like', 'the', 'dead', 'havent', 'slept', 'so', 'long', 'feeling', 'sad', 'dread', 'im', 'talking', 'to', 'myself', 'forgot', 'what', 'just', 'said', 'cause', 'im', 'all', 'messed', 'up', 'making', 'prefect', 'nonsense', 'drowning', 'in', 'my', 'doubt', 'too', 'well', 'cause', 'im', 'all', 'messed', 'up', 'going', 'nowhere', 'fast', 'but', 'circles', 'in', 'my', 'mind', 'so', 'blind', 'well', 'hold', 'my', 'only', 'enemy', 'as', 'closely', 'as', 'friend', 'and', 'sold', 'my', 'own', 'reality', 'to', 'further', 'my', 'descent', 'selfdestruction', 'taking', 'over', 'its', 'so', 'easy', 'to', 'pretend', 'introduction', 'to', 'this', 'nightmare', 'may', 'never', 'end', 'can', 'anyone', 'help', 'me', 'drag', 'my', 'heels', 'im', 'running', 'overtime', 'cant', 'hold', 'down', 'my', 'meals', 'my', 'mind', 'is', 'racing', 'by', 'staring', 'blankly', 'feels', 'like', 'pulling', 'out', 'my', 'teeth', 'while', 'this', 'engine', 'winds', 'cause', 'im', 'all', 'messed', 'up', 'making', 'prefect', 'nonsense', 'drowning', 'in', 'my', 'doubt', 'too', 'well', 'cause', 'im', 'all', 'messed', 'up', 'going', 'nowhere', 'fast', 'but', 'circles', 'in', 'my', 'mind', 'so', 'blind']\n"
     ]
    }
   ],
   "source": [
    "# Stemming with word_tokenize in train_data\n",
    "tokens_train = word_tokenize(train_data['Lyrics'][1])\n",
    "print(tokens_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anoth', 'day', 'wast', 'out', 'of', 'time', 'cant', 'get', 'out', 'of', 'thi', 'alter', 'state', 'of', 'mind', 'im', 'go', 'overboard', 'my', 'conscienc', 'meet', 'declin', 'into', 'realiti', 'know', 'thi', 'cant', 'be', 'fine', 'caus', 'im', 'all', 'mess', 'up', 'make', 'prefect', 'nonsens', 'drown', 'in', 'my', 'doubt', 'too', 'well', 'caus', 'im', 'all', 'mess', 'up', 'go', 'nowher', 'fast', 'but', 'circl', 'in', 'my', 'mind', 'so', 'blind', 'who', 'are', 'these', 'voic', 'in', 'my', 'head', 'cant', 'go', 'on', 'like', 'thi', 'live', 'like', 'the', 'dead', 'havent', 'slept', 'so', 'long', 'feel', 'sad', 'dread', 'im', 'talk', 'to', 'myself', 'forgot', 'what', 'just', 'said', 'caus', 'im', 'all', 'mess', 'up', 'make', 'prefect', 'nonsens', 'drown', 'in', 'my', 'doubt', 'too', 'well', 'caus', 'im', 'all', 'mess', 'up', 'go', 'nowher', 'fast', 'but', 'circl', 'in', 'my', 'mind', 'so', 'blind', 'well', 'hold', 'my', 'onli', 'enemi', 'as', 'close', 'as', 'friend', 'and', 'sold', 'my', 'own', 'realiti', 'to', 'further', 'my', 'descent', 'selfdestruct', 'take', 'over', 'it', 'so', 'easi', 'to', 'pretend', 'introduct', 'to', 'thi', 'nightmar', 'may', 'never', 'end', 'can', 'anyon', 'help', 'me', 'drag', 'my', 'heel', 'im', 'run', 'overtim', 'cant', 'hold', 'down', 'my', 'meal', 'my', 'mind', 'is', 'race', 'by', 'stare', 'blankli', 'feel', 'like', 'pull', 'out', 'my', 'teeth', 'while', 'thi', 'engin', 'wind', 'caus', 'im', 'all', 'mess', 'up', 'make', 'prefect', 'nonsens', 'drown', 'in', 'my', 'doubt', 'too', 'well', 'caus', 'im', 'all', 'mess', 'up', 'go', 'nowher', 'fast', 'but', 'circl', 'in', 'my', 'mind', 'so', 'blind']\n"
     ]
    }
   ],
   "source": [
    "# Stemming with PorterStemmer in train_data\n",
    "porter = PorterStemmer()\n",
    "pStems = [porter.stem(t) for t in tokens_train]\n",
    "print(pStems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anoth', 'day', 'wast', 'out', 'of', 'tim', 'cant', 'get', 'out', 'of', 'thi', 'alt', 'stat', 'of', 'mind', 'im', 'going', 'overboard', 'my', 'conscy', 'meet', 'declin', 'into', 'real', 'know', 'thi', 'cant', 'be', 'fin', 'caus', 'im', 'al', 'mess', 'up', 'mak', 'prefect', 'nonsens', 'drown', 'in', 'my', 'doubt', 'too', 'wel', 'caus', 'im', 'al', 'mess', 'up', 'going', 'nowh', 'fast', 'but', 'circ', 'in', 'my', 'mind', 'so', 'blind', 'who', 'ar', 'thes', 'voic', 'in', 'my', 'head', 'cant', 'go', 'on', 'lik', 'thi', 'liv', 'lik', 'the', 'dead', 'hav', 'slept', 'so', 'long', 'feel', 'sad', 'dread', 'im', 'talk', 'to', 'myself', 'forgot', 'what', 'just', 'said', 'caus', 'im', 'al', 'mess', 'up', 'mak', 'prefect', 'nonsens', 'drown', 'in', 'my', 'doubt', 'too', 'wel', 'caus', 'im', 'al', 'mess', 'up', 'going', 'nowh', 'fast', 'but', 'circ', 'in', 'my', 'mind', 'so', 'blind', 'wel', 'hold', 'my', 'on', 'enemy', 'as', 'clos', 'as', 'friend', 'and', 'sold', 'my', 'own', 'real', 'to', 'furth', 'my', 'desc', 'selfdestruct', 'tak', 'ov', 'it', 'so', 'easy', 'to', 'pretend', 'introduc', 'to', 'thi', 'nightm', 'may', 'nev', 'end', 'can', 'anyon', 'help', 'me', 'drag', 'my', 'heel', 'im', 'run', 'overtim', 'cant', 'hold', 'down', 'my', 'meal', 'my', 'mind', 'is', 'rac', 'by', 'star', 'blank', 'feel', 'lik', 'pul', 'out', 'my', 'tee', 'whil', 'thi', 'engin', 'wind', 'caus', 'im', 'al', 'mess', 'up', 'mak', 'prefect', 'nonsens', 'drown', 'in', 'my', 'doubt', 'too', 'wel', 'caus', 'im', 'al', 'mess', 'up', 'going', 'nowh', 'fast', 'but', 'circ', 'in', 'my', 'mind', 'so', 'blind']\n"
     ]
    }
   ],
   "source": [
    "# Stemming with LancasterStemmer in train_data\n",
    "lancaster = LancasterStemmer()\n",
    "lStems = [lancaster.stem(t) for t in tokens_train]\n",
    "print(lStems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'we', 'can', 'pop', 'bottles', 'all', 'night', 'baby', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'gas', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'baby', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'anytime', 'you', 'want', 'to', 'pick', 'up', 'the', 'telephone', 'you', 'know', 'it', 'aint', 'nothin', 'to', 'drop', 'couple', 'stacks', 'on', 'you', 'wanted', 'you', 'could', 'get', 'it', 'my', 'dear', 'five', 'million', 'dollar', 'home', 'drop', 'bentleys', 'swear', 'yeah', 'wantcho', 'body', 'need', 'yo', 'body', 'long', 'as', 'you', 'got', 'me', 'you', 'wont', 'need', 'nobody', 'you', 'want', 'it', 'got', 'it', 'go', 'get', 'it', 'buy', 'it', 'tell', 'em', 'other', 'broke', 'brothers', 'be', 'quiet', 'stacks', 'on', 'deck', 'patrone', 'on', 'ice', 'and', 'we', 'can', 'pop', 'bottles', 'all', 'night', 'baby', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'gas', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'baby', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'shawty', 'you', 'da', 'hottest', 'love', 'the', 'way', 'you', 'drop', 'it', 'brain', 'so', 'good', 'good', 'coulda', 'swore', 'you', 'went', 'to', 'college', 'hundred', 'deposits', 'vacations', 'hit', 'the', 'tropics', 'cause', 'errbody', 'know', 'it', 'aint', 'trickin', 'if', 'ya', 'got', 'it', 'ya', 'need', 'to', 'never', 'ever', 'got', 'ta', 'go', 'to', 'yo', 'wallet', 'long', 'as', 'got', 'rubberband', 'banks', 'in', 'my', 'pocket', 'five', 'six', 'rides', 'with', 'rims', 'and', 'body', 'kit', 'ya', 'aint', 'got', 'ta', 'downgrade', 'you', 'can', 'get', 'what', 'get', 'my', 'chick', 'can', 'have', 'what', 'she', 'want', 'and', 'go', 'in', 'every', 'store', 'for', 'any', 'bag', 'she', 'want', 'and', 'know', 'she', 'aint', 'never', 'had', 'man', 'like', 'that', 'to', 'buy', 'ya', 'anything', 'your', 'heart', 'desire', 'like', 'that', 'yeah', 'wantcho', 'body', 'need', 'yo', 'body', 'long', 'as', 'you', 'got', 'me', 'you', 'wont', 'need', 'nobody', 'you', 'want', 'it', 'got', 'it', 'go', 'get', 'it', 'buy', 'it', 'tellem', 'other', 'broke', 'niggas', 'be', 'quiet', 'stacks', 'on', 'deck', 'patrone', 'on', 'ice', 'and', 'we', 'can', 'pop', 'bottles', 'all', 'night', 'baby', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'gas', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'baby', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'im', 'talkin', 'big', 'boy', 'rides', 'and', 'big', 'boy', 'ice', 'let', 'me', 'put', 'this', 'big', 'boy', 'in', 'yo', 'life']\n"
     ]
    }
   ],
   "source": [
    "# Stemming with word_tokenize in test_data\n",
    "tokens_test = word_tokenize(test_data['Lyrics'][102])\n",
    "print(tokens_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'we', 'can', 'pop', 'bottl', 'all', 'night', 'babi', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'ga', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'babi', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'anytim', 'you', 'want', 'to', 'pick', 'up', 'the', 'telephon', 'you', 'know', 'it', 'aint', 'nothin', 'to', 'drop', 'coupl', 'stack', 'on', 'you', 'want', 'you', 'could', 'get', 'it', 'my', 'dear', 'five', 'million', 'dollar', 'home', 'drop', 'bentley', 'swear', 'yeah', 'wantcho', 'bodi', 'need', 'yo', 'bodi', 'long', 'as', 'you', 'got', 'me', 'you', 'wont', 'need', 'nobodi', 'you', 'want', 'it', 'got', 'it', 'go', 'get', 'it', 'buy', 'it', 'tell', 'em', 'other', 'broke', 'brother', 'be', 'quiet', 'stack', 'on', 'deck', 'patron', 'on', 'ice', 'and', 'we', 'can', 'pop', 'bottl', 'all', 'night', 'babi', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'ga', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'babi', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'shawti', 'you', 'da', 'hottest', 'love', 'the', 'way', 'you', 'drop', 'it', 'brain', 'so', 'good', 'good', 'coulda', 'swore', 'you', 'went', 'to', 'colleg', 'hundr', 'deposit', 'vacat', 'hit', 'the', 'tropic', 'caus', 'errbodi', 'know', 'it', 'aint', 'trickin', 'if', 'ya', 'got', 'it', 'ya', 'need', 'to', 'never', 'ever', 'got', 'ta', 'go', 'to', 'yo', 'wallet', 'long', 'as', 'got', 'rubberband', 'bank', 'in', 'my', 'pocket', 'five', 'six', 'ride', 'with', 'rim', 'and', 'bodi', 'kit', 'ya', 'aint', 'got', 'ta', 'downgrad', 'you', 'can', 'get', 'what', 'get', 'my', 'chick', 'can', 'have', 'what', 'she', 'want', 'and', 'go', 'in', 'everi', 'store', 'for', 'ani', 'bag', 'she', 'want', 'and', 'know', 'she', 'aint', 'never', 'had', 'man', 'like', 'that', 'to', 'buy', 'ya', 'anyth', 'your', 'heart', 'desir', 'like', 'that', 'yeah', 'wantcho', 'bodi', 'need', 'yo', 'bodi', 'long', 'as', 'you', 'got', 'me', 'you', 'wont', 'need', 'nobodi', 'you', 'want', 'it', 'got', 'it', 'go', 'get', 'it', 'buy', 'it', 'tellem', 'other', 'broke', 'nigga', 'be', 'quiet', 'stack', 'on', 'deck', 'patron', 'on', 'ice', 'and', 'we', 'can', 'pop', 'bottl', 'all', 'night', 'babi', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'ga', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'babi', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'im', 'talkin', 'big', 'boy', 'ride', 'and', 'big', 'boy', 'ice', 'let', 'me', 'put', 'thi', 'big', 'boy', 'in', 'yo', 'life']\n"
     ]
    }
   ],
   "source": [
    "# Stemming with PorterStemmer in test_data\n",
    "porter = PorterStemmer()\n",
    "pStems = [porter.stem(t) for t in tokens_test]\n",
    "print(pStems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'we', 'can', 'pop', 'bottl', 'al', 'night', 'baby', 'you', 'can', 'hav', 'whatev', 'you', 'lik', 'you', 'lik', 'said', 'you', 'can', 'hav', 'whatev', 'you', 'lik', 'you', 'lik', 'yeah', 'lat', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'il', 'gas', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'baby', 'you', 'can', 'go', 'wher', 'ev', 'you', 'lik', 'you', 'lik', 'said', 'you', 'can', 'go', 'wher', 'ev', 'you', 'lik', 'you', 'lik', 'yeah', 'anytim', 'you', 'want', 'to', 'pick', 'up', 'the', 'telephon', 'you', 'know', 'it', 'aint', 'nothin', 'to', 'drop', 'coupl', 'stack', 'on', 'you', 'want', 'you', 'could', 'get', 'it', 'my', 'dear', 'fiv', 'mil', 'doll', 'hom', 'drop', 'bentley', 'swear', 'yeah', 'wantcho', 'body', 'nee', 'yo', 'body', 'long', 'as', 'you', 'got', 'me', 'you', 'wont', 'nee', 'nobody', 'you', 'want', 'it', 'got', 'it', 'go', 'get', 'it', 'buy', 'it', 'tel', 'em', 'oth', 'brok', 'broth', 'be', 'quiet', 'stack', 'on', 'deck', 'patron', 'on', 'ic', 'and', 'we', 'can', 'pop', 'bottl', 'al', 'night', 'baby', 'you', 'can', 'hav', 'whatev', 'you', 'lik', 'you', 'lik', 'said', 'you', 'can', 'hav', 'whatev', 'you', 'lik', 'you', 'lik', 'yeah', 'lat', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'il', 'gas', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'baby', 'you', 'can', 'go', 'wher', 'ev', 'you', 'lik', 'you', 'lik', 'said', 'you', 'can', 'go', 'wher', 'ev', 'you', 'lik', 'you', 'lik', 'yeah', 'shawty', 'you', 'da', 'hottest', 'lov', 'the', 'way', 'you', 'drop', 'it', 'brain', 'so', 'good', 'good', 'could', 'swor', 'you', 'went', 'to', 'colleg', 'hundr', 'deposit', 'vac', 'hit', 'the', 'trop', 'caus', 'errbody', 'know', 'it', 'aint', 'trickin', 'if', 'ya', 'got', 'it', 'ya', 'nee', 'to', 'nev', 'ev', 'got', 'ta', 'go', 'to', 'yo', 'wallet', 'long', 'as', 'got', 'rubberband', 'bank', 'in', 'my', 'pocket', 'fiv', 'six', 'rid', 'with', 'rim', 'and', 'body', 'kit', 'ya', 'aint', 'got', 'ta', 'downgrad', 'you', 'can', 'get', 'what', 'get', 'my', 'chick', 'can', 'hav', 'what', 'she', 'want', 'and', 'go', 'in', 'every', 'stor', 'for', 'any', 'bag', 'she', 'want', 'and', 'know', 'she', 'aint', 'nev', 'had', 'man', 'lik', 'that', 'to', 'buy', 'ya', 'anyth', 'yo', 'heart', 'desir', 'lik', 'that', 'yeah', 'wantcho', 'body', 'nee', 'yo', 'body', 'long', 'as', 'you', 'got', 'me', 'you', 'wont', 'nee', 'nobody', 'you', 'want', 'it', 'got', 'it', 'go', 'get', 'it', 'buy', 'it', 'tellem', 'oth', 'brok', 'nigga', 'be', 'quiet', 'stack', 'on', 'deck', 'patron', 'on', 'ic', 'and', 'we', 'can', 'pop', 'bottl', 'al', 'night', 'baby', 'you', 'can', 'hav', 'whatev', 'you', 'lik', 'you', 'lik', 'said', 'you', 'can', 'hav', 'whatev', 'you', 'lik', 'you', 'lik', 'yeah', 'lat', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'il', 'gas', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'baby', 'you', 'can', 'go', 'wher', 'ev', 'you', 'lik', 'you', 'lik', 'said', 'you', 'can', 'go', 'wher', 'ev', 'you', 'lik', 'you', 'lik', 'yeah', 'im', 'talkin', 'big', 'boy', 'rid', 'and', 'big', 'boy', 'ic', 'let', 'me', 'put', 'thi', 'big', 'boy', 'in', 'yo', 'lif']\n"
     ]
    }
   ],
   "source": [
    "# Stemming with LancasterStemmer in train_data\n",
    "lancaster = LancasterStemmer()\n",
    "lStems = [lancaster.stem(t) for t in tokens_test]\n",
    "print(lStems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['another', 'day', 'wasted', 'out', 'of', 'time', 'cant', 'get', 'out', 'of', 'this', 'altered', 'state', 'of', 'mind', 'im', 'going', 'overboard', 'my', 'conscience', 'meets', 'decline', 'into', 'reality', 'know', 'this', 'cant', 'be', 'fine', 'cause', 'im', 'all', 'messed', 'up', 'making', 'prefect', 'nonsense', 'drowning', 'in', 'my', 'doubt', 'too', 'well', 'cause', 'im', 'all', 'messed', 'up', 'going', 'nowhere', 'fast', 'but', 'circles', 'in', 'my', 'mind', 'so', 'blind', 'who', 'are', 'these', 'voices', 'in', 'my', 'head', 'cant', 'go', 'on', 'like', 'this', 'living', 'like', 'the', 'dead', 'havent', 'slept', 'so', 'long', 'feeling', 'sad', 'dread', 'im', 'talking', 'to', 'myself', 'forgot', 'what', 'just', 'said', 'cause', 'im', 'all', 'messed', 'up', 'making', 'prefect', 'nonsense', 'drowning', 'in', 'my', 'doubt', 'too', 'well', 'cause', 'im', 'all', 'messed', 'up', 'going', 'nowhere', 'fast', 'but', 'circles', 'in', 'my', 'mind', 'so', 'blind', 'well', 'hold', 'my', 'only', 'enemy', 'as', 'closely', 'as', 'friend', 'and', 'sold', 'my', 'own', 'reality', 'to', 'further', 'my', 'descent', 'selfdestruction', 'taking', 'over', 'its', 'so', 'easy', 'to', 'pretend', 'introduction', 'to', 'this', 'nightmare', 'may', 'never', 'end', 'can', 'anyone', 'help', 'me', 'drag', 'my', 'heels', 'im', 'running', 'overtime', 'cant', 'hold', 'down', 'my', 'meals', 'my', 'mind', 'is', 'racing', 'by', 'staring', 'blankly', 'feels', 'like', 'pulling', 'out', 'my', 'teeth', 'while', 'this', 'engine', 'winds', 'cause', 'im', 'all', 'messed', 'up', 'making', 'prefect', 'nonsense', 'drowning', 'in', 'my', 'doubt', 'too', 'well', 'cause', 'im', 'all', 'messed', 'up', 'going', 'nowhere', 'fast', 'but', 'circles', 'in', 'my', 'mind', 'so', 'blind']\n"
     ]
    }
   ],
   "source": [
    "# Stemming with PorterStemmer in train_data\n",
    "tokens_train = word_tokenize(train_data['Lyrics'][1])\n",
    "print(tokens_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['another', 'day', 'wasted', 'out', 'of', 'time', 'cant', 'get', 'out', 'of', 'this', 'altered', 'state', 'of', 'mind', 'im', 'going', 'overboard', 'my', 'conscience', 'meet', 'decline', 'into', 'reality', 'know', 'this', 'cant', 'be', 'fine', 'cause', 'im', 'all', 'messed', 'up', 'making', 'prefect', 'nonsense', 'drowning', 'in', 'my', 'doubt', 'too', 'well', 'cause', 'im', 'all', 'messed', 'up', 'going', 'nowhere', 'fast', 'but', 'circle', 'in', 'my', 'mind', 'so', 'blind', 'who', 'are', 'these', 'voice', 'in', 'my', 'head', 'cant', 'go', 'on', 'like', 'this', 'living', 'like', 'the', 'dead', 'havent', 'slept', 'so', 'long', 'feeling', 'sad', 'dread', 'im', 'talking', 'to', 'myself', 'forgot', 'what', 'just', 'said', 'cause', 'im', 'all', 'messed', 'up', 'making', 'prefect', 'nonsense', 'drowning', 'in', 'my', 'doubt', 'too', 'well', 'cause', 'im', 'all', 'messed', 'up', 'going', 'nowhere', 'fast', 'but', 'circle', 'in', 'my', 'mind', 'so', 'blind', 'well', 'hold', 'my', 'only', 'enemy', 'a', 'closely', 'a', 'friend', 'and', 'sold', 'my', 'own', 'reality', 'to', 'further', 'my', 'descent', 'selfdestruction', 'taking', 'over', 'it', 'so', 'easy', 'to', 'pretend', 'introduction', 'to', 'this', 'nightmare', 'may', 'never', 'end', 'can', 'anyone', 'help', 'me', 'drag', 'my', 'heel', 'im', 'running', 'overtime', 'cant', 'hold', 'down', 'my', 'meal', 'my', 'mind', 'is', 'racing', 'by', 'staring', 'blankly', 'feel', 'like', 'pulling', 'out', 'my', 'teeth', 'while', 'this', 'engine', 'wind', 'cause', 'im', 'all', 'messed', 'up', 'making', 'prefect', 'nonsense', 'drowning', 'in', 'my', 'doubt', 'too', 'well', 'cause', 'im', 'all', 'messed', 'up', 'going', 'nowhere', 'fast', 'but', 'circle', 'in', 'my', 'mind', 'so', 'blind']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization with WordNetLemmatizer in train_data\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmas = [lemmatizer.lemmatize(t) for t in tokens_train]\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'we', 'can', 'pop', 'bottl', 'all', 'night', 'babi', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'ga', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'babi', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'anytim', 'you', 'want', 'to', 'pick', 'up', 'the', 'telephon', 'you', 'know', 'it', 'aint', 'nothin', 'to', 'drop', 'coupl', 'stack', 'on', 'you', 'want', 'you', 'could', 'get', 'it', 'my', 'dear', 'five', 'million', 'dollar', 'home', 'drop', 'bentley', 'swear', 'yeah', 'wantcho', 'bodi', 'need', 'yo', 'bodi', 'long', 'as', 'you', 'got', 'me', 'you', 'wont', 'need', 'nobodi', 'you', 'want', 'it', 'got', 'it', 'go', 'get', 'it', 'buy', 'it', 'tell', 'em', 'other', 'broke', 'brother', 'be', 'quiet', 'stack', 'on', 'deck', 'patron', 'on', 'ice', 'and', 'we', 'can', 'pop', 'bottl', 'all', 'night', 'babi', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'ga', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'babi', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'shawti', 'you', 'da', 'hottest', 'love', 'the', 'way', 'you', 'drop', 'it', 'brain', 'so', 'good', 'good', 'coulda', 'swore', 'you', 'went', 'to', 'colleg', 'hundr', 'deposit', 'vacat', 'hit', 'the', 'tropic', 'caus', 'errbodi', 'know', 'it', 'aint', 'trickin', 'if', 'ya', 'got', 'it', 'ya', 'need', 'to', 'never', 'ever', 'got', 'ta', 'go', 'to', 'yo', 'wallet', 'long', 'as', 'got', 'rubberband', 'bank', 'in', 'my', 'pocket', 'five', 'six', 'ride', 'with', 'rim', 'and', 'bodi', 'kit', 'ya', 'aint', 'got', 'ta', 'downgrad', 'you', 'can', 'get', 'what', 'get', 'my', 'chick', 'can', 'have', 'what', 'she', 'want', 'and', 'go', 'in', 'everi', 'store', 'for', 'ani', 'bag', 'she', 'want', 'and', 'know', 'she', 'aint', 'never', 'had', 'man', 'like', 'that', 'to', 'buy', 'ya', 'anyth', 'your', 'heart', 'desir', 'like', 'that', 'yeah', 'wantcho', 'bodi', 'need', 'yo', 'bodi', 'long', 'as', 'you', 'got', 'me', 'you', 'wont', 'need', 'nobodi', 'you', 'want', 'it', 'got', 'it', 'go', 'get', 'it', 'buy', 'it', 'tellem', 'other', 'broke', 'nigga', 'be', 'quiet', 'stack', 'on', 'deck', 'patron', 'on', 'ice', 'and', 'we', 'can', 'pop', 'bottl', 'all', 'night', 'babi', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'ga', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'babi', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'im', 'talkin', 'big', 'boy', 'ride', 'and', 'big', 'boy', 'ice', 'let', 'me', 'put', 'thi', 'big', 'boy', 'in', 'yo', 'life']\n"
     ]
    }
   ],
   "source": [
    "# Stemming with PorterStemmer in test_data\n",
    "porter = PorterStemmer()\n",
    "pStems = [porter.stem(t) for t in tokens_test]\n",
    "print(pStems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'we', 'can', 'pop', 'bottle', 'all', 'night', 'baby', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'gas', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'baby', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'anytime', 'you', 'want', 'to', 'pick', 'up', 'the', 'telephone', 'you', 'know', 'it', 'aint', 'nothin', 'to', 'drop', 'couple', 'stack', 'on', 'you', 'wanted', 'you', 'could', 'get', 'it', 'my', 'dear', 'five', 'million', 'dollar', 'home', 'drop', 'bentleys', 'swear', 'yeah', 'wantcho', 'body', 'need', 'yo', 'body', 'long', 'a', 'you', 'got', 'me', 'you', 'wont', 'need', 'nobody', 'you', 'want', 'it', 'got', 'it', 'go', 'get', 'it', 'buy', 'it', 'tell', 'em', 'other', 'broke', 'brother', 'be', 'quiet', 'stack', 'on', 'deck', 'patrone', 'on', 'ice', 'and', 'we', 'can', 'pop', 'bottle', 'all', 'night', 'baby', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'gas', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'baby', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'shawty', 'you', 'da', 'hottest', 'love', 'the', 'way', 'you', 'drop', 'it', 'brain', 'so', 'good', 'good', 'coulda', 'swore', 'you', 'went', 'to', 'college', 'hundred', 'deposit', 'vacation', 'hit', 'the', 'tropic', 'cause', 'errbody', 'know', 'it', 'aint', 'trickin', 'if', 'ya', 'got', 'it', 'ya', 'need', 'to', 'never', 'ever', 'got', 'ta', 'go', 'to', 'yo', 'wallet', 'long', 'a', 'got', 'rubberband', 'bank', 'in', 'my', 'pocket', 'five', 'six', 'ride', 'with', 'rim', 'and', 'body', 'kit', 'ya', 'aint', 'got', 'ta', 'downgrade', 'you', 'can', 'get', 'what', 'get', 'my', 'chick', 'can', 'have', 'what', 'she', 'want', 'and', 'go', 'in', 'every', 'store', 'for', 'any', 'bag', 'she', 'want', 'and', 'know', 'she', 'aint', 'never', 'had', 'man', 'like', 'that', 'to', 'buy', 'ya', 'anything', 'your', 'heart', 'desire', 'like', 'that', 'yeah', 'wantcho', 'body', 'need', 'yo', 'body', 'long', 'a', 'you', 'got', 'me', 'you', 'wont', 'need', 'nobody', 'you', 'want', 'it', 'got', 'it', 'go', 'get', 'it', 'buy', 'it', 'tellem', 'other', 'broke', 'nigga', 'be', 'quiet', 'stack', 'on', 'deck', 'patrone', 'on', 'ice', 'and', 'we', 'can', 'pop', 'bottle', 'all', 'night', 'baby', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'gas', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'baby', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'im', 'talkin', 'big', 'boy', 'ride', 'and', 'big', 'boy', 'ice', 'let', 'me', 'put', 'this', 'big', 'boy', 'in', 'yo', 'life']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization with WordNetLemmatizer in train_data\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmas = [lemmatizer.lemmatize(t) for t in tokens_test]\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
