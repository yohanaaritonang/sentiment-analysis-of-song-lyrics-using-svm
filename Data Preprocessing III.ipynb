{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 549 ms\n",
      "Wall time: 55.5 ms\n"
     ]
    }
   ],
   "source": [
    "%time train_data = pd.read_csv(\"Train.csv\", delimiter=',', index_col =0)\n",
    "%time test_data = pd.read_csv(\"Test.csv\", delimiter=',', index_col =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist's Name</th>\n",
       "      <th>Duration of Music (seconds)</th>\n",
       "      <th>Category</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SongID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Littlest Things</td>\n",
       "      <td>Lily Allen</td>\n",
       "      <td>186</td>\n",
       "      <td>happy</td>\n",
       "      <td>Sometimes I find myself sittin' back and remin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Fun.</td>\n",
       "      <td>All The Pretty Girls</td>\n",
       "      <td>203</td>\n",
       "      <td>happy</td>\n",
       "      <td>All the pretty girls on a Saturday night So I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Funny Little Frog</td>\n",
       "      <td>belle and sebastian</td>\n",
       "      <td>188</td>\n",
       "      <td>happy</td>\n",
       "      <td>Honey lovin you is the greatest thing I get to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>I Was Only Joking</td>\n",
       "      <td>Rod Stewart</td>\n",
       "      <td>367</td>\n",
       "      <td>relaxed</td>\n",
       "      <td>Ever since I was a kid at school I messed arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Alone (2000 Digital Remaster)</td>\n",
       "      <td>Heart</td>\n",
       "      <td>222</td>\n",
       "      <td>sad</td>\n",
       "      <td>i hear the ticking of the clock I'm lying here...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Song Name         Artist's Name  \\\n",
       "SongID                                                        \n",
       "187                   Littlest Things            Lily Allen   \n",
       "141                              Fun.  All The Pretty Girls   \n",
       "142                 Funny Little Frog   belle and sebastian   \n",
       "348                 I Was Only Joking           Rod Stewart   \n",
       "211     Alone (2000 Digital Remaster)                 Heart   \n",
       "\n",
       "        Duration of Music (seconds) Category  \\\n",
       "SongID                                         \n",
       "187                             186    happy   \n",
       "141                             203    happy   \n",
       "142                             188    happy   \n",
       "348                             367  relaxed   \n",
       "211                             222      sad   \n",
       "\n",
       "                                                   Lyrics  \n",
       "SongID                                                     \n",
       "187     Sometimes I find myself sittin' back and remin...  \n",
       "141     All the pretty girls on a Saturday night So I ...  \n",
       "142     Honey lovin you is the greatest thing I get to...  \n",
       "348     Ever since I was a kid at school I messed arou...  \n",
       "211     i hear the ticking of the clock I'm lying here...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist's Name</th>\n",
       "      <th>Duration of Music (seconds)</th>\n",
       "      <th>Category</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SongID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>So Bad</td>\n",
       "      <td>Eminem</td>\n",
       "      <td>867</td>\n",
       "      <td>angry</td>\n",
       "      <td>You feel that baby? Yeah I feel it too Damn Yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Windmills Of Your Mind</td>\n",
       "      <td>Sting</td>\n",
       "      <td>259</td>\n",
       "      <td>relaxed</td>\n",
       "      <td>round like a circle in a spiral like a wheel w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Please, Please, Please Let Me Get What I Want</td>\n",
       "      <td>The Smiths</td>\n",
       "      <td>112</td>\n",
       "      <td>sad</td>\n",
       "      <td>Good times for a change See, the luck I\\'ve ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Rush</td>\n",
       "      <td>Talib Kweli</td>\n",
       "      <td>222</td>\n",
       "      <td>angry</td>\n",
       "      <td>Rush - Talib Kweli Feel the rush Yeah, I do th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lullaby</td>\n",
       "      <td>The Cure</td>\n",
       "      <td>253</td>\n",
       "      <td>sad</td>\n",
       "      <td>on candystripe legs the spiderman comes softly...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Song Name Artist's Name  \\\n",
       "SongID                                                                \n",
       "21                                             So Bad        Eminem   \n",
       "95                             Windmills Of Your Mind         Sting   \n",
       "36      Please, Please, Please Let Me Get What I Want    The Smiths   \n",
       "12                                               Rush   Talib Kweli   \n",
       "10                                            Lullaby      The Cure   \n",
       "\n",
       "        Duration of Music (seconds) Category  \\\n",
       "SongID                                         \n",
       "21                              867    angry   \n",
       "95                              259  relaxed   \n",
       "36                              112      sad   \n",
       "12                              222    angry   \n",
       "10                              253      sad   \n",
       "\n",
       "                                                   Lyrics  \n",
       "SongID                                                     \n",
       "21      You feel that baby? Yeah I feel it too Damn Yo...  \n",
       "95      round like a circle in a spiral like a wheel w...  \n",
       "36      Good times for a change See, the luck I\\'ve ha...  \n",
       "12      Rush - Talib Kweli Feel the rush Yeah, I do th...  \n",
       "10      on candystripe legs the spiderman comes softly...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting the Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist's Name</th>\n",
       "      <th>Duration of Music (seconds)</th>\n",
       "      <th>Category</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SongID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Song Name  Artist's Name  Duration of Music (seconds)  Category  \\\n",
       "SongID                                                                    \n",
       "1           False          False                        False     False   \n",
       "2           False          False                        False     False   \n",
       "3           False          False                        False     False   \n",
       "4           False          False                        False     False   \n",
       "5           False          False                        False     False   \n",
       "...           ...            ...                          ...       ...   \n",
       "396         False          False                        False     False   \n",
       "397         False          False                        False     False   \n",
       "398         False          False                        False     False   \n",
       "399         False          False                        False     False   \n",
       "400         False          False                        False     False   \n",
       "\n",
       "        Lyrics  \n",
       "SongID          \n",
       "1        False  \n",
       "2        False  \n",
       "3        False  \n",
       "4        False  \n",
       "5        False  \n",
       "...        ...  \n",
       "396      False  \n",
       "397      False  \n",
       "398      False  \n",
       "399      False  \n",
       "400      False  \n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist's Name</th>\n",
       "      <th>Duration of Music (seconds)</th>\n",
       "      <th>Category</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SongID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Song Name  Artist's Name  Duration of Music (seconds)  Category  \\\n",
       "SongID                                                                    \n",
       "1           False          False                        False     False   \n",
       "2           False          False                        False     False   \n",
       "3           False          False                        False     False   \n",
       "4           False          False                        False     False   \n",
       "5           False          False                        False     False   \n",
       "...           ...            ...                          ...       ...   \n",
       "97          False          False                        False     False   \n",
       "98          False          False                        False     False   \n",
       "99          False          False                        False     False   \n",
       "100         False          False                        False     False   \n",
       "101         False          False                        False     False   \n",
       "\n",
       "        Lyrics  \n",
       "SongID          \n",
       "1        False  \n",
       "2        False  \n",
       "3        False  \n",
       "4        False  \n",
       "5        False  \n",
       "...        ...  \n",
       "97       False  \n",
       "98       False  \n",
       "99       False  \n",
       "100      False  \n",
       "101      False  \n",
       "\n",
       "[378 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing the Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Song Name                      0\n",
       "Artist's Name                  0\n",
       "Duration of Music (seconds)    0\n",
       "Category                       0\n",
       "Lyrics                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Song Name                      0\n",
       "Artist's Name                  0\n",
       "Duration of Music (seconds)    0\n",
       "Category                       0\n",
       "Lyrics                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column does not contain Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Case Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Lyrics'] = train_data['Lyrics'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SongID\n",
      "1      another day wasted out of time i can't get out...\n",
      "2      crawl from the wreckage one more time horrific...\n",
      "3      don't wanna be an american idiot.  don't want ...\n",
      "4      the more of you that i inspect the more of me ...\n",
      "5      the prophets of god have left you solaced inde...\n",
      "                             ...                        \n",
      "396    over the rainbow what a wonderful world \"orion...\n",
      "397    the sunshineâs come, the flowers dance along...\n",
      "398    this stone that i have swallowed isn't goin do...\n",
      "399    love is like an aero plane you jump and then y...\n",
      "400    wise men say wise men say wise men say the bad...\n",
      "Name: Lyrics, Length: 400, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_Lyrics = train_data.iloc[:400]\n",
    "print(train_Lyrics['Lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Lyrics'] = test_data['Lyrics'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SongID\n",
      "1      sometimes you just feel tired, feel weak when ...\n",
      "2      too late for the other side caught in a change...\n",
      "3      cast your eyes into the distance try to focus ...\n",
      "4      look like ass, smell like shit why are you suc...\n",
      "5      you find me offensive i find you offensive for...\n",
      "                             ...                        \n",
      "97     the bluest skies don't seem so blue and the st...\n",
      "98     you are my sunshine, my only sunshine you make...\n",
      "99     see the pyramids along the nile watch the sunr...\n",
      "100    see the pyramids along the nile watch the sun ...\n",
      "101    staring at the moon so blue turning all my tho...\n",
      "Name: Lyrics, Length: 378, dtype: object\n"
     ]
    }
   ],
   "source": [
    "test_Lyrics = test_data.iloc[:400]\n",
    "print(test_Lyrics['Lyrics'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\ITD-\n",
      "[nltk_data]     STU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegexpTokenizer(pattern=SongID\n",
      "1      another day wasted out of time i can't get out...\n",
      "2      crawl from the wreckage one more time horrific...\n",
      "3      don't wanna be an american idiot.  don't want ...\n",
      "4      the more of you that i inspect the more of me ...\n",
      "5      the prophets of god have left you solaced inde...\n",
      "                             ...                        \n",
      "396    over the rainbow what a wonderful world \"orion...\n",
      "397    the sunshineâs come, the flowers dance along...\n",
      "398    this stone that i have swallowed isn't goin do...\n",
      "399    love is like an aero plane you jump and then y...\n",
      "400    wise men say wise men say wise men say the bad...\n",
      "Name: Lyrics, Length: 400, dtype: object, gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>)\n"
     ]
    }
   ],
   "source": [
    "Regtokenizer = RegexpTokenizer(train_Lyrics['Lyrics'])\n",
    "print(Regtokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegexpTokenizer(pattern=SongID\n",
      "1      sometimes you just feel tired, feel weak when ...\n",
      "2      too late for the other side caught in a change...\n",
      "3      cast your eyes into the distance try to focus ...\n",
      "4      look like ass, smell like shit why are you suc...\n",
      "5      you find me offensive i find you offensive for...\n",
      "                             ...                        \n",
      "97     the bluest skies don't seem so blue and the st...\n",
      "98     you are my sunshine, my only sunshine you make...\n",
      "99     see the pyramids along the nile watch the sunr...\n",
      "100    see the pyramids along the nile watch the sun ...\n",
      "101    staring at the moon so blue turning all my tho...\n",
      "Name: Lyrics, Length: 378, dtype: object, gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>)\n"
     ]
    }
   ],
   "source": [
    "Regtokenizer = RegexpTokenizer(test_Lyrics['Lyrics'])\n",
    "print(Regtokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing Result : \n",
      "\n",
      "SongID\n",
      "1      [another, day, wasted, out, of, time, cant, ge...\n",
      "2      [crawl, from, the, wreckage, one, more, time, ...\n",
      "3      [dont, wan, na, be, an, american, idiot, dont,...\n",
      "4      [the, more, of, you, that, inspect, the, more,...\n",
      "5      [the, prophets, of, god, have, left, you, sola...\n",
      "                             ...                        \n",
      "396    [over, the, rainbow, what, wonderful, world, o...\n",
      "397    [the, sunshineâ, come, the, flowers, dance, ...\n",
      "398    [this, stone, that, have, swallowed, isnt, goi...\n",
      "399    [love, is, like, an, aero, plane, you, jump, a...\n",
      "400    [wise, men, say, wise, men, say, wise, men, sa...\n",
      "Name: Lyrics_tokens, Length: 400, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "import re\n",
    "#remove number\n",
    "def remove_number(text):\n",
    "    return  re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "train_data['Lyrics'] = train_data['Lyrics'].apply(remove_number)\n",
    "\n",
    "#remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "\n",
    "train_data['Lyrics'] = train_data['Lyrics'].apply(remove_punctuation)\n",
    "\n",
    "#remove whitespace leading & trailing\n",
    "def remove_whitespace_LT(text):\n",
    "    return text.strip()\n",
    "\n",
    "train_data['Lyrics'] = train_data['Lyrics'].apply(remove_whitespace_LT)\n",
    "\n",
    "#remove multiple whitespace into single whitespace\n",
    "def remove_whitespace_multiple(text):\n",
    "    return re.sub('\\s+',' ',text)\n",
    "\n",
    "train_data['Lyrics'] = train_data['Lyrics'].apply(remove_whitespace_multiple)\n",
    "\n",
    "# remove single char\n",
    "def remove_singl_char(text):\n",
    "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "\n",
    "train_data['Lyrics'] = train_data['Lyrics'].apply(remove_singl_char)\n",
    "\n",
    "# NLTK word tokenize \n",
    "def word_tokenize_wrapper(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "train_data['Lyrics_tokens']= train_data['Lyrics'].apply(word_tokenize_wrapper)\n",
    "\n",
    "print('Tokenizing Result : \\n') \n",
    "print(train_data['Lyrics_tokens'])\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist's Name</th>\n",
       "      <th>Duration of Music (seconds)</th>\n",
       "      <th>Category</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Lyrics_tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SongID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Pancake</td>\n",
       "      <td>Tori Amos</td>\n",
       "      <td>357</td>\n",
       "      <td>angry</td>\n",
       "      <td>im not sure whos fooling who here as im watchi...</td>\n",
       "      <td>[im, not, sure, whos, fooling, who, here, as, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Costume Makes The Clown</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>192</td>\n",
       "      <td>angry</td>\n",
       "      <td>told you  felt lucky with my humble breasts we...</td>\n",
       "      <td>[told, you, felt, lucky, with, my, humble, bre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Another Time Around</td>\n",
       "      <td>Sum 41</td>\n",
       "      <td>416</td>\n",
       "      <td>angry</td>\n",
       "      <td>in my years ive seen all sounds of misconcepti...</td>\n",
       "      <td>[in, my, years, ive, seen, all, sounds, of, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>How Could I</td>\n",
       "      <td>Marc Anthony</td>\n",
       "      <td>270</td>\n",
       "      <td>sad</td>\n",
       "      <td>ohummm it was  coldest day in december  day  a...</td>\n",
       "      <td>[ohummm, it, was, coldest, day, in, december, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Innocent</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>302</td>\n",
       "      <td>sad</td>\n",
       "      <td>guess you really did it this time left yoursel...</td>\n",
       "      <td>[guess, you, really, did, it, this, time, left...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Song Name Artist's Name  Duration of Music (seconds)  \\\n",
       "SongID                                                                       \n",
       "92                      Pancake     Tori Amos                          357   \n",
       "21      Costume Makes The Clown       Shakira                          192   \n",
       "6           Another Time Around        Sum 41                          416   \n",
       "275                 How Could I  Marc Anthony                          270   \n",
       "287                    Innocent  Taylor Swift                          302   \n",
       "\n",
       "       Category                                             Lyrics  \\\n",
       "SongID                                                               \n",
       "92        angry  im not sure whos fooling who here as im watchi...   \n",
       "21        angry  told you  felt lucky with my humble breasts we...   \n",
       "6         angry  in my years ive seen all sounds of misconcepti...   \n",
       "275         sad  ohummm it was  coldest day in december  day  a...   \n",
       "287         sad  guess you really did it this time left yoursel...   \n",
       "\n",
       "                                            Lyrics_tokens  \n",
       "SongID                                                     \n",
       "92      [im, not, sure, whos, fooling, who, here, as, ...  \n",
       "21      [told, you, felt, lucky, with, my, humble, bre...  \n",
       "6       [in, my, years, ive, seen, all, sounds, of, mi...  \n",
       "275     [ohummm, it, was, coldest, day, in, december, ...  \n",
       "287     [guess, you, really, did, it, this, time, left...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing Result : \n",
      "\n",
      "SongID\n",
      "1      [sometimes, you, just, feel, tired, feel, weak...\n",
      "2      [too, late, for, the, other, side, caught, in,...\n",
      "3      [cast, your, eyes, into, the, distance, try, t...\n",
      "4      [look, like, ass, smell, like, shit, why, are,...\n",
      "5      [you, find, me, offensive, find, you, offensiv...\n",
      "                             ...                        \n",
      "97     [the, bluest, skies, dont, seem, so, blue, and...\n",
      "98     [you, are, my, sunshine, my, only, sunshine, y...\n",
      "99     [see, the, pyramids, along, the, nile, watch, ...\n",
      "100    [see, the, pyramids, along, the, nile, watch, ...\n",
      "101    [staring, at, the, moon, so, blue, turning, al...\n",
      "Name: Lyrics_tokens, Length: 378, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "import re\n",
    "#remove number\n",
    "def remove_number(text):\n",
    "    return  re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "test_data['Lyrics'] = test_data['Lyrics'].apply(remove_number)\n",
    "\n",
    "#remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "\n",
    "test_data['Lyrics'] = test_data['Lyrics'].apply(remove_punctuation)\n",
    "\n",
    "#remove whitespace leading & trailing\n",
    "def remove_whitespace_LT(text):\n",
    "    return text.strip()\n",
    "\n",
    "test_data['Lyrics'] = test_data['Lyrics'].apply(remove_whitespace_LT)\n",
    "\n",
    "#remove multiple whitespace into single whitespace\n",
    "def remove_whitespace_multiple(text):\n",
    "    return re.sub('\\s+',' ',text)\n",
    "\n",
    "test_data['Lyrics'] = test_data['Lyrics'].apply(remove_whitespace_multiple)\n",
    "\n",
    "# remove single char\n",
    "def remove_singl_char(text):\n",
    "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "\n",
    "test_data['Lyrics'] = test_data['Lyrics'].apply(remove_singl_char)\n",
    "\n",
    "# NLTK word tokenize \n",
    "def word_tokenize_wrapper(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "test_data['Lyrics_tokens']= test_data['Lyrics'].apply(word_tokenize_wrapper)\n",
    "\n",
    "print('Tokenizing Result : \\n') \n",
    "print(test_data['Lyrics_tokens'])\n",
    "print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist's Name</th>\n",
       "      <th>Duration of Music (seconds)</th>\n",
       "      <th>Category</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Lyrics_tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SongID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Mean</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>242</td>\n",
       "      <td>happy</td>\n",
       "      <td>you with your words like knives and swords and...</td>\n",
       "      <td>[you, with, your, words, like, knives, and, sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Wanna Be Close</td>\n",
       "      <td>Avant</td>\n",
       "      <td>227</td>\n",
       "      <td>relaxed</td>\n",
       "      <td>wanna be girl let me be  wanna be everything ...</td>\n",
       "      <td>[wan, na, be, girl, let, me, be, wan, na, be, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Maybe California</td>\n",
       "      <td>Tori Amos</td>\n",
       "      <td>265</td>\n",
       "      <td>sad</td>\n",
       "      <td>hey mrs  please donâ jump why not nothing is...</td>\n",
       "      <td>[hey, mrs, please, donâ, jump, why, not, not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Sad News</td>\n",
       "      <td>Chris Garneau</td>\n",
       "      <td>364</td>\n",
       "      <td>relaxed</td>\n",
       "      <td>should have killed you myself it was always  ...</td>\n",
       "      <td>[should, have, killed, you, myself, it, was, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>On Top Of The World</td>\n",
       "      <td>Imagine Dragons</td>\n",
       "      <td>507</td>\n",
       "      <td>happy</td>\n",
       "      <td>if you love somebody better tell them while th...</td>\n",
       "      <td>[if, you, love, somebody, better, tell, them, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Song Name    Artist's Name  Duration of Music (seconds)  \\\n",
       "SongID                                                                      \n",
       "25                     Mean     Taylor Swift                          242   \n",
       "87           Wanna Be Close            Avant                          227   \n",
       "15         Maybe California        Tori Amos                          265   \n",
       "39                 Sad News    Chris Garneau                          364   \n",
       "37      On Top Of The World  Imagine Dragons                          507   \n",
       "\n",
       "       Category                                             Lyrics  \\\n",
       "SongID                                                               \n",
       "25        happy  you with your words like knives and swords and...   \n",
       "87      relaxed   wanna be girl let me be  wanna be everything ...   \n",
       "15          sad  hey mrs  please donâ jump why not nothing is...   \n",
       "39      relaxed   should have killed you myself it was always  ...   \n",
       "37        happy  if you love somebody better tell them while th...   \n",
       "\n",
       "                                            Lyrics_tokens  \n",
       "SongID                                                     \n",
       "25      [you, with, your, words, like, knives, and, sw...  \n",
       "87      [wan, na, be, girl, let, me, be, wan, na, be, ...  \n",
       "15      [hey, mrs, please, donâ, jump, why, not, not...  \n",
       "39      [should, have, killed, you, myself, it, was, a...  \n",
       "37      [if, you, love, somebody, better, tell, them, ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stopwords Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\ITD-\n",
      "[nltk_data]     STU\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print (stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SongID\n",
      "1      [another, day, wasted, time, cant, get, altere...\n",
      "2      [crawl, wreckage, one, time, horrific, memory,...\n",
      "3      [dont, wan, na, american, idiot, dont, want, n...\n",
      "4      [inspect, see, reflect, try, read, lips, mask,...\n",
      "5      [prophets, god, left, solaced, indeed, zombie,...\n",
      "                             ...                        \n",
      "396    [rainbow, wonderful, world, orion, somewhere, ...\n",
      "397    [sunshineâ, come, flowers, dance, along, riv...\n",
      "398    [stone, swallowed, isnt, goin, well, road, fol...\n",
      "399    [love, like, aero, plane, jump, pray, lucky, o...\n",
      "400    [wise, men, say, wise, men, say, wise, men, sa...\n",
      "Name: Lyrics_tokens_SW, Length: 400, dtype: object\n"
     ]
    }
   ],
   "source": [
    "list_stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def stopwords_removal(words):\n",
    "    return [word for word in words if word not in list_stopwords]\n",
    "train_data['Lyrics_tokens_SW'] = train_data['Lyrics_tokens'].apply(stopwords_removal) \n",
    "print(train_data['Lyrics_tokens_SW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist's Name</th>\n",
       "      <th>Duration of Music (seconds)</th>\n",
       "      <th>Category</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Lyrics_tokens</th>\n",
       "      <th>Lyrics_tokens_SW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SongID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Free</td>\n",
       "      <td>Good Lovelies</td>\n",
       "      <td>177</td>\n",
       "      <td>happy</td>\n",
       "      <td>keep my lid on tightly  dress the part and sm...</td>\n",
       "      <td>[keep, my, lid, on, tightly, dress, the, part,...</td>\n",
       "      <td>[keep, lid, tightly, dress, part, smile, somet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>I Miss You</td>\n",
       "      <td>Darren Hayes</td>\n",
       "      <td>333</td>\n",
       "      <td>relaxed</td>\n",
       "      <td>gimme  reason why im feeling so blue everytime...</td>\n",
       "      <td>[gim, me, reason, why, im, feeling, so, blue, ...</td>\n",
       "      <td>[gim, reason, im, feeling, blue, everytime, cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Hot Air Balloon</td>\n",
       "      <td>Owl City</td>\n",
       "      <td>568</td>\n",
       "      <td>happy</td>\n",
       "      <td>we wrote  prelude to our own fairy tale and bo...</td>\n",
       "      <td>[we, wrote, prelude, to, our, own, fairy, tale...</td>\n",
       "      <td>[wrote, prelude, fairy, tale, bought, parachut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Be Alright</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>191</td>\n",
       "      <td>sad</td>\n",
       "      <td>across the ocean across the sea startin to for...</td>\n",
       "      <td>[across, the, ocean, across, the, sea, startin...</td>\n",
       "      <td>[across, ocean, across, sea, startin, forget, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>I Was Only Joking</td>\n",
       "      <td>Rod Stewart</td>\n",
       "      <td>367</td>\n",
       "      <td>relaxed</td>\n",
       "      <td>ever since  was  kid at school  messed around ...</td>\n",
       "      <td>[ever, since, was, kid, at, school, messed, ar...</td>\n",
       "      <td>[ever, since, kid, school, messed, around, rul...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Song Name  Artist's Name  Duration of Music (seconds)  \\\n",
       "SongID                                                                  \n",
       "140                  Free  Good Lovelies                          177   \n",
       "345            I Miss You   Darren Hayes                          333   \n",
       "161       Hot Air Balloon       Owl City                          568   \n",
       "216            Be Alright  Justin Bieber                          191   \n",
       "348     I Was Only Joking    Rod Stewart                          367   \n",
       "\n",
       "       Category                                             Lyrics  \\\n",
       "SongID                                                               \n",
       "140       happy   keep my lid on tightly  dress the part and sm...   \n",
       "345     relaxed  gimme  reason why im feeling so blue everytime...   \n",
       "161       happy  we wrote  prelude to our own fairy tale and bo...   \n",
       "216         sad  across the ocean across the sea startin to for...   \n",
       "348     relaxed  ever since  was  kid at school  messed around ...   \n",
       "\n",
       "                                            Lyrics_tokens  \\\n",
       "SongID                                                      \n",
       "140     [keep, my, lid, on, tightly, dress, the, part,...   \n",
       "345     [gim, me, reason, why, im, feeling, so, blue, ...   \n",
       "161     [we, wrote, prelude, to, our, own, fairy, tale...   \n",
       "216     [across, the, ocean, across, the, sea, startin...   \n",
       "348     [ever, since, was, kid, at, school, messed, ar...   \n",
       "\n",
       "                                         Lyrics_tokens_SW  \n",
       "SongID                                                     \n",
       "140     [keep, lid, tightly, dress, part, smile, somet...  \n",
       "345     [gim, reason, im, feeling, blue, everytime, cl...  \n",
       "161     [wrote, prelude, fairy, tale, bought, parachut...  \n",
       "216     [across, ocean, across, sea, startin, forget, ...  \n",
       "348     [ever, since, kid, school, messed, around, rul...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SongID\n",
      "1      [sometimes, feel, tired, feel, weak, feel, wea...\n",
      "2      [late, side, caught, change, life, late, side,...\n",
      "3      [cast, eyes, distance, try, focus, find, spiri...\n",
      "4      [look, like, ass, smell, like, shit, dick, wal...\n",
      "5      [find, offensive, find, offensive, finding, of...\n",
      "                             ...                        \n",
      "97     [bluest, skies, dont, seem, blue, stars, seem,...\n",
      "98     [sunshine, sunshine, make, happy, skies, gray,...\n",
      "99     [see, pyramids, along, nile, watch, sunrise, t...\n",
      "100    [see, pyramids, along, nile, watch, sun, rise,...\n",
      "101    [staring, moon, blue, turning, thoughts, witho...\n",
      "Name: Lyrics_tokens_SW, Length: 378, dtype: object\n"
     ]
    }
   ],
   "source": [
    "list_stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def stopwords_removal(words):\n",
    "    return [word for word in words if word not in list_stopwords]\n",
    "test_data['Lyrics_tokens_SW'] = test_data['Lyrics_tokens'].apply(stopwords_removal) \n",
    "print(test_data['Lyrics_tokens_SW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist's Name</th>\n",
       "      <th>Duration of Music (seconds)</th>\n",
       "      <th>Category</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Lyrics_tokens</th>\n",
       "      <th>Lyrics_tokens_SW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SongID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Sometimes I Feel So Lonely</td>\n",
       "      <td>Primal Scream</td>\n",
       "      <td>306</td>\n",
       "      <td>sad</td>\n",
       "      <td>you can be redeemed boy you can be redeemed li...</td>\n",
       "      <td>[you, can, be, redeemed, boy, you, can, be, re...</td>\n",
       "      <td>[redeemed, boy, redeemed, life, dream, boy, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Amazing Grace</td>\n",
       "      <td>Olivia Ong</td>\n",
       "      <td>251</td>\n",
       "      <td>relaxed</td>\n",
       "      <td>amazing grace how sweet the sound that saved  ...</td>\n",
       "      <td>[amazing, grace, how, sweet, the, sound, that,...</td>\n",
       "      <td>[amazing, grace, sweet, sound, saved, wretch, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ridin'</td>\n",
       "      <td>Chamillionaire,sway</td>\n",
       "      <td>272</td>\n",
       "      <td>angry</td>\n",
       "      <td>they see me rolling they hating patrolling the...</td>\n",
       "      <td>[they, see, me, rolling, they, hating, patroll...</td>\n",
       "      <td>[see, rolling, hating, patrolling, tryin, catc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Violet</td>\n",
       "      <td>Hole</td>\n",
       "      <td>207</td>\n",
       "      <td>angry</td>\n",
       "      <td>and the sky was made of amethyst and all the s...</td>\n",
       "      <td>[and, the, sky, was, made, of, amethyst, and, ...</td>\n",
       "      <td>[sky, made, amethyst, stars, look, like, littl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Spade</td>\n",
       "      <td>Marilyn Manson</td>\n",
       "      <td>282</td>\n",
       "      <td>angry</td>\n",
       "      <td>the beauty spot was borrowed and now my sweet ...</td>\n",
       "      <td>[the, beauty, spot, was, borrowed, and, now, m...</td>\n",
       "      <td>[beauty, spot, borrowed, sweet, knife, rusts, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Song Name        Artist's Name  \\\n",
       "SongID                                                    \n",
       "52      Sometimes I Feel So Lonely        Primal Scream   \n",
       "14                   Amazing Grace           Olivia Ong   \n",
       "10                          Ridin'  Chamillionaire,sway   \n",
       "61                          Violet                 Hole   \n",
       "29                           Spade       Marilyn Manson   \n",
       "\n",
       "        Duration of Music (seconds) Category  \\\n",
       "SongID                                         \n",
       "52                              306      sad   \n",
       "14                              251  relaxed   \n",
       "10                              272    angry   \n",
       "61                              207    angry   \n",
       "29                              282    angry   \n",
       "\n",
       "                                                   Lyrics  \\\n",
       "SongID                                                      \n",
       "52      you can be redeemed boy you can be redeemed li...   \n",
       "14      amazing grace how sweet the sound that saved  ...   \n",
       "10      they see me rolling they hating patrolling the...   \n",
       "61      and the sky was made of amethyst and all the s...   \n",
       "29      the beauty spot was borrowed and now my sweet ...   \n",
       "\n",
       "                                            Lyrics_tokens  \\\n",
       "SongID                                                      \n",
       "52      [you, can, be, redeemed, boy, you, can, be, re...   \n",
       "14      [amazing, grace, how, sweet, the, sound, that,...   \n",
       "10      [they, see, me, rolling, they, hating, patroll...   \n",
       "61      [and, the, sky, was, made, of, amethyst, and, ...   \n",
       "29      [the, beauty, spot, was, borrowed, and, now, m...   \n",
       "\n",
       "                                         Lyrics_tokens_SW  \n",
       "SongID                                                     \n",
       "52      [redeemed, boy, redeemed, life, dream, boy, re...  \n",
       "14      [amazing, grace, sweet, sound, saved, wretch, ...  \n",
       "10      [see, rolling, hating, patrolling, tryin, catc...  \n",
       "61      [sky, made, amethyst, stars, look, like, littl...  \n",
       "29      [beauty, spot, borrowed, sweet, knife, rusts, ...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer, LancasterStemmer, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming in train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['another', 'day', 'wasted', 'out', 'of', 'time', 'cant', 'get', 'out', 'of', 'this', 'altered', 'state', 'of', 'mind', 'im', 'going', 'overboard', 'my', 'conscience', 'meets', 'decline', 'into', 'reality', 'know', 'this', 'cant', 'be', 'fine', 'cause', 'im', 'all', 'messed', 'up', 'making', 'prefect', 'nonsense', 'drowning', 'in', 'my', 'doubt', 'too', 'well', 'cause', 'im', 'all', 'messed', 'up', 'going', 'nowhere', 'fast', 'but', 'circles', 'in', 'my', 'mind', 'so', 'blind', 'who', 'are', 'these', 'voices', 'in', 'my', 'head', 'cant', 'go', 'on', 'like', 'this', 'living', 'like', 'the', 'dead', 'havent', 'slept', 'so', 'long', 'feeling', 'sad', 'dread', 'im', 'talking', 'to', 'myself', 'forgot', 'what', 'just', 'said', 'cause', 'im', 'all', 'messed', 'up', 'making', 'prefect', 'nonsense', 'drowning', 'in', 'my', 'doubt', 'too', 'well', 'cause', 'im', 'all', 'messed', 'up', 'going', 'nowhere', 'fast', 'but', 'circles', 'in', 'my', 'mind', 'so', 'blind', 'well', 'hold', 'my', 'only', 'enemy', 'as', 'closely', 'as', 'friend', 'and', 'sold', 'my', 'own', 'reality', 'to', 'further', 'my', 'descent', 'selfdestruction', 'taking', 'over', 'its', 'so', 'easy', 'to', 'pretend', 'introduction', 'to', 'this', 'nightmare', 'may', 'never', 'end', 'can', 'anyone', 'help', 'me', 'drag', 'my', 'heels', 'im', 'running', 'overtime', 'cant', 'hold', 'down', 'my', 'meals', 'my', 'mind', 'is', 'racing', 'by', 'staring', 'blankly', 'feels', 'like', 'pulling', 'out', 'my', 'teeth', 'while', 'this', 'engine', 'winds', 'cause', 'im', 'all', 'messed', 'up', 'making', 'prefect', 'nonsense', 'drowning', 'in', 'my', 'doubt', 'too', 'well', 'cause', 'im', 'all', 'messed', 'up', 'going', 'nowhere', 'fast', 'but', 'circles', 'in', 'my', 'mind', 'so', 'blind']\n"
     ]
    }
   ],
   "source": [
    "tokens_train = train_data['Lyrics_tokens'][1]\n",
    "print(tokens_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anoth', 'day', 'wast', 'out', 'of', 'time', 'cant', 'get', 'out', 'of', 'thi', 'alter', 'state', 'of', 'mind', 'im', 'go', 'overboard', 'my', 'conscienc', 'meet', 'declin', 'into', 'realiti', 'know', 'thi', 'cant', 'be', 'fine', 'caus', 'im', 'all', 'mess', 'up', 'make', 'prefect', 'nonsens', 'drown', 'in', 'my', 'doubt', 'too', 'well', 'caus', 'im', 'all', 'mess', 'up', 'go', 'nowher', 'fast', 'but', 'circl', 'in', 'my', 'mind', 'so', 'blind', 'who', 'are', 'these', 'voic', 'in', 'my', 'head', 'cant', 'go', 'on', 'like', 'thi', 'live', 'like', 'the', 'dead', 'havent', 'slept', 'so', 'long', 'feel', 'sad', 'dread', 'im', 'talk', 'to', 'myself', 'forgot', 'what', 'just', 'said', 'caus', 'im', 'all', 'mess', 'up', 'make', 'prefect', 'nonsens', 'drown', 'in', 'my', 'doubt', 'too', 'well', 'caus', 'im', 'all', 'mess', 'up', 'go', 'nowher', 'fast', 'but', 'circl', 'in', 'my', 'mind', 'so', 'blind', 'well', 'hold', 'my', 'onli', 'enemi', 'as', 'close', 'as', 'friend', 'and', 'sold', 'my', 'own', 'realiti', 'to', 'further', 'my', 'descent', 'selfdestruct', 'take', 'over', 'it', 'so', 'easi', 'to', 'pretend', 'introduct', 'to', 'thi', 'nightmar', 'may', 'never', 'end', 'can', 'anyon', 'help', 'me', 'drag', 'my', 'heel', 'im', 'run', 'overtim', 'cant', 'hold', 'down', 'my', 'meal', 'my', 'mind', 'is', 'race', 'by', 'stare', 'blankli', 'feel', 'like', 'pull', 'out', 'my', 'teeth', 'while', 'thi', 'engin', 'wind', 'caus', 'im', 'all', 'mess', 'up', 'make', 'prefect', 'nonsens', 'drown', 'in', 'my', 'doubt', 'too', 'well', 'caus', 'im', 'all', 'mess', 'up', 'go', 'nowher', 'fast', 'but', 'circl', 'in', 'my', 'mind', 'so', 'blind']\n"
     ]
    }
   ],
   "source": [
    "# Stemming with PorterStemmer in train_data\n",
    "porter = PorterStemmer()\n",
    "pStems = [porter.stem(t) for t in tokens_train]\n",
    "print(pStems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anoth', 'day', 'wast', 'out', 'of', 'tim', 'cant', 'get', 'out', 'of', 'thi', 'alt', 'stat', 'of', 'mind', 'im', 'going', 'overboard', 'my', 'conscy', 'meet', 'declin', 'into', 'real', 'know', 'thi', 'cant', 'be', 'fin', 'caus', 'im', 'al', 'mess', 'up', 'mak', 'prefect', 'nonsens', 'drown', 'in', 'my', 'doubt', 'too', 'wel', 'caus', 'im', 'al', 'mess', 'up', 'going', 'nowh', 'fast', 'but', 'circ', 'in', 'my', 'mind', 'so', 'blind', 'who', 'ar', 'thes', 'voic', 'in', 'my', 'head', 'cant', 'go', 'on', 'lik', 'thi', 'liv', 'lik', 'the', 'dead', 'hav', 'slept', 'so', 'long', 'feel', 'sad', 'dread', 'im', 'talk', 'to', 'myself', 'forgot', 'what', 'just', 'said', 'caus', 'im', 'al', 'mess', 'up', 'mak', 'prefect', 'nonsens', 'drown', 'in', 'my', 'doubt', 'too', 'wel', 'caus', 'im', 'al', 'mess', 'up', 'going', 'nowh', 'fast', 'but', 'circ', 'in', 'my', 'mind', 'so', 'blind', 'wel', 'hold', 'my', 'on', 'enemy', 'as', 'clos', 'as', 'friend', 'and', 'sold', 'my', 'own', 'real', 'to', 'furth', 'my', 'desc', 'selfdestruct', 'tak', 'ov', 'it', 'so', 'easy', 'to', 'pretend', 'introduc', 'to', 'thi', 'nightm', 'may', 'nev', 'end', 'can', 'anyon', 'help', 'me', 'drag', 'my', 'heel', 'im', 'run', 'overtim', 'cant', 'hold', 'down', 'my', 'meal', 'my', 'mind', 'is', 'rac', 'by', 'star', 'blank', 'feel', 'lik', 'pul', 'out', 'my', 'tee', 'whil', 'thi', 'engin', 'wind', 'caus', 'im', 'al', 'mess', 'up', 'mak', 'prefect', 'nonsens', 'drown', 'in', 'my', 'doubt', 'too', 'wel', 'caus', 'im', 'al', 'mess', 'up', 'going', 'nowh', 'fast', 'but', 'circ', 'in', 'my', 'mind', 'so', 'blind']\n"
     ]
    }
   ],
   "source": [
    "# Stemming with LancasterStemmer in train_data\n",
    "lancaster = LancasterStemmer()\n",
    "lStems = [lancaster.stem(t) for t in tokens_train]\n",
    "print(lStems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'we', 'can', 'pop', 'bottles', 'all', 'night', 'baby', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'gas', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'baby', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'anytime', 'you', 'want', 'to', 'pick', 'up', 'the', 'telephone', 'you', 'know', 'it', 'aint', 'nothin', 'to', 'drop', 'couple', 'stacks', 'on', 'you', 'wanted', 'you', 'could', 'get', 'it', 'my', 'dear', 'five', 'million', 'dollar', 'home', 'drop', 'bentleys', 'swear', 'yeah', 'wantcho', 'body', 'need', 'yo', 'body', 'long', 'as', 'you', 'got', 'me', 'you', 'wont', 'need', 'nobody', 'you', 'want', 'it', 'got', 'it', 'go', 'get', 'it', 'buy', 'it', 'tell', 'em', 'other', 'broke', 'brothers', 'be', 'quiet', 'stacks', 'on', 'deck', 'patrone', 'on', 'ice', 'and', 'we', 'can', 'pop', 'bottles', 'all', 'night', 'baby', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'gas', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'baby', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'shawty', 'you', 'da', 'hottest', 'love', 'the', 'way', 'you', 'drop', 'it', 'brain', 'so', 'good', 'good', 'coulda', 'swore', 'you', 'went', 'to', 'college', 'hundred', 'deposits', 'vacations', 'hit', 'the', 'tropics', 'cause', 'errbody', 'know', 'it', 'aint', 'trickin', 'if', 'ya', 'got', 'it', 'ya', 'need', 'to', 'never', 'ever', 'got', 'ta', 'go', 'to', 'yo', 'wallet', 'long', 'as', 'got', 'rubberband', 'banks', 'in', 'my', 'pocket', 'five', 'six', 'rides', 'with', 'rims', 'and', 'body', 'kit', 'ya', 'aint', 'got', 'ta', 'downgrade', 'you', 'can', 'get', 'what', 'get', 'my', 'chick', 'can', 'have', 'what', 'she', 'want', 'and', 'go', 'in', 'every', 'store', 'for', 'any', 'bag', 'she', 'want', 'and', 'know', 'she', 'aint', 'never', 'had', 'man', 'like', 'that', 'to', 'buy', 'ya', 'anything', 'your', 'heart', 'desire', 'like', 'that', 'yeah', 'wantcho', 'body', 'need', 'yo', 'body', 'long', 'as', 'you', 'got', 'me', 'you', 'wont', 'need', 'nobody', 'you', 'want', 'it', 'got', 'it', 'go', 'get', 'it', 'buy', 'it', 'tellem', 'other', 'broke', 'niggas', 'be', 'quiet', 'stacks', 'on', 'deck', 'patrone', 'on', 'ice', 'and', 'we', 'can', 'pop', 'bottles', 'all', 'night', 'baby', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'gas', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'baby', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'im', 'talkin', 'big', 'boy', 'rides', 'and', 'big', 'boy', 'ice', 'let', 'me', 'put', 'this', 'big', 'boy', 'in', 'yo', 'life']\n"
     ]
    }
   ],
   "source": [
    "# Stemming with word_tokenize in test_data\n",
    "tokens_test = word_tokenize(test_data['Lyrics'][102])\n",
    "print(tokens_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'we', 'can', 'pop', 'bottl', 'all', 'night', 'babi', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'ga', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'babi', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'anytim', 'you', 'want', 'to', 'pick', 'up', 'the', 'telephon', 'you', 'know', 'it', 'aint', 'nothin', 'to', 'drop', 'coupl', 'stack', 'on', 'you', 'want', 'you', 'could', 'get', 'it', 'my', 'dear', 'five', 'million', 'dollar', 'home', 'drop', 'bentley', 'swear', 'yeah', 'wantcho', 'bodi', 'need', 'yo', 'bodi', 'long', 'as', 'you', 'got', 'me', 'you', 'wont', 'need', 'nobodi', 'you', 'want', 'it', 'got', 'it', 'go', 'get', 'it', 'buy', 'it', 'tell', 'em', 'other', 'broke', 'brother', 'be', 'quiet', 'stack', 'on', 'deck', 'patron', 'on', 'ice', 'and', 'we', 'can', 'pop', 'bottl', 'all', 'night', 'babi', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'ga', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'babi', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'shawti', 'you', 'da', 'hottest', 'love', 'the', 'way', 'you', 'drop', 'it', 'brain', 'so', 'good', 'good', 'coulda', 'swore', 'you', 'went', 'to', 'colleg', 'hundr', 'deposit', 'vacat', 'hit', 'the', 'tropic', 'caus', 'errbodi', 'know', 'it', 'aint', 'trickin', 'if', 'ya', 'got', 'it', 'ya', 'need', 'to', 'never', 'ever', 'got', 'ta', 'go', 'to', 'yo', 'wallet', 'long', 'as', 'got', 'rubberband', 'bank', 'in', 'my', 'pocket', 'five', 'six', 'ride', 'with', 'rim', 'and', 'bodi', 'kit', 'ya', 'aint', 'got', 'ta', 'downgrad', 'you', 'can', 'get', 'what', 'get', 'my', 'chick', 'can', 'have', 'what', 'she', 'want', 'and', 'go', 'in', 'everi', 'store', 'for', 'ani', 'bag', 'she', 'want', 'and', 'know', 'she', 'aint', 'never', 'had', 'man', 'like', 'that', 'to', 'buy', 'ya', 'anyth', 'your', 'heart', 'desir', 'like', 'that', 'yeah', 'wantcho', 'bodi', 'need', 'yo', 'bodi', 'long', 'as', 'you', 'got', 'me', 'you', 'wont', 'need', 'nobodi', 'you', 'want', 'it', 'got', 'it', 'go', 'get', 'it', 'buy', 'it', 'tellem', 'other', 'broke', 'nigga', 'be', 'quiet', 'stack', 'on', 'deck', 'patron', 'on', 'ice', 'and', 'we', 'can', 'pop', 'bottl', 'all', 'night', 'babi', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'ga', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'babi', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'im', 'talkin', 'big', 'boy', 'ride', 'and', 'big', 'boy', 'ice', 'let', 'me', 'put', 'thi', 'big', 'boy', 'in', 'yo', 'life']\n"
     ]
    }
   ],
   "source": [
    "# Stemming with PorterStemmer in test_data\n",
    "porter = PorterStemmer()\n",
    "pStems = [porter.stem(t) for t in tokens_test]\n",
    "print(pStems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'we', 'can', 'pop', 'bottl', 'al', 'night', 'baby', 'you', 'can', 'hav', 'whatev', 'you', 'lik', 'you', 'lik', 'said', 'you', 'can', 'hav', 'whatev', 'you', 'lik', 'you', 'lik', 'yeah', 'lat', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'il', 'gas', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'baby', 'you', 'can', 'go', 'wher', 'ev', 'you', 'lik', 'you', 'lik', 'said', 'you', 'can', 'go', 'wher', 'ev', 'you', 'lik', 'you', 'lik', 'yeah', 'anytim', 'you', 'want', 'to', 'pick', 'up', 'the', 'telephon', 'you', 'know', 'it', 'aint', 'nothin', 'to', 'drop', 'coupl', 'stack', 'on', 'you', 'want', 'you', 'could', 'get', 'it', 'my', 'dear', 'fiv', 'mil', 'doll', 'hom', 'drop', 'bentley', 'swear', 'yeah', 'wantcho', 'body', 'nee', 'yo', 'body', 'long', 'as', 'you', 'got', 'me', 'you', 'wont', 'nee', 'nobody', 'you', 'want', 'it', 'got', 'it', 'go', 'get', 'it', 'buy', 'it', 'tel', 'em', 'oth', 'brok', 'broth', 'be', 'quiet', 'stack', 'on', 'deck', 'patron', 'on', 'ic', 'and', 'we', 'can', 'pop', 'bottl', 'al', 'night', 'baby', 'you', 'can', 'hav', 'whatev', 'you', 'lik', 'you', 'lik', 'said', 'you', 'can', 'hav', 'whatev', 'you', 'lik', 'you', 'lik', 'yeah', 'lat', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'il', 'gas', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'baby', 'you', 'can', 'go', 'wher', 'ev', 'you', 'lik', 'you', 'lik', 'said', 'you', 'can', 'go', 'wher', 'ev', 'you', 'lik', 'you', 'lik', 'yeah', 'shawty', 'you', 'da', 'hottest', 'lov', 'the', 'way', 'you', 'drop', 'it', 'brain', 'so', 'good', 'good', 'could', 'swor', 'you', 'went', 'to', 'colleg', 'hundr', 'deposit', 'vac', 'hit', 'the', 'trop', 'caus', 'errbody', 'know', 'it', 'aint', 'trickin', 'if', 'ya', 'got', 'it', 'ya', 'nee', 'to', 'nev', 'ev', 'got', 'ta', 'go', 'to', 'yo', 'wallet', 'long', 'as', 'got', 'rubberband', 'bank', 'in', 'my', 'pocket', 'fiv', 'six', 'rid', 'with', 'rim', 'and', 'body', 'kit', 'ya', 'aint', 'got', 'ta', 'downgrad', 'you', 'can', 'get', 'what', 'get', 'my', 'chick', 'can', 'hav', 'what', 'she', 'want', 'and', 'go', 'in', 'every', 'stor', 'for', 'any', 'bag', 'she', 'want', 'and', 'know', 'she', 'aint', 'nev', 'had', 'man', 'lik', 'that', 'to', 'buy', 'ya', 'anyth', 'yo', 'heart', 'desir', 'lik', 'that', 'yeah', 'wantcho', 'body', 'nee', 'yo', 'body', 'long', 'as', 'you', 'got', 'me', 'you', 'wont', 'nee', 'nobody', 'you', 'want', 'it', 'got', 'it', 'go', 'get', 'it', 'buy', 'it', 'tellem', 'oth', 'brok', 'nigga', 'be', 'quiet', 'stack', 'on', 'deck', 'patron', 'on', 'ic', 'and', 'we', 'can', 'pop', 'bottl', 'al', 'night', 'baby', 'you', 'can', 'hav', 'whatev', 'you', 'lik', 'you', 'lik', 'said', 'you', 'can', 'hav', 'whatev', 'you', 'lik', 'you', 'lik', 'yeah', 'lat', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'il', 'gas', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'baby', 'you', 'can', 'go', 'wher', 'ev', 'you', 'lik', 'you', 'lik', 'said', 'you', 'can', 'go', 'wher', 'ev', 'you', 'lik', 'you', 'lik', 'yeah', 'im', 'talkin', 'big', 'boy', 'rid', 'and', 'big', 'boy', 'ic', 'let', 'me', 'put', 'thi', 'big', 'boy', 'in', 'yo', 'lif']\n"
     ]
    }
   ],
   "source": [
    "# Stemming with LancasterStemmer in train_data\n",
    "lancaster = LancasterStemmer()\n",
    "lStems = [lancaster.stem(t) for t in tokens_test]\n",
    "print(lStems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['another', 'day', 'wasted', 'out', 'of', 'time', 'cant', 'get', 'out', 'of', 'this', 'altered', 'state', 'of', 'mind', 'im', 'going', 'overboard', 'my', 'conscience', 'meets', 'decline', 'into', 'reality', 'know', 'this', 'cant', 'be', 'fine', 'cause', 'im', 'all', 'messed', 'up', 'making', 'prefect', 'nonsense', 'drowning', 'in', 'my', 'doubt', 'too', 'well', 'cause', 'im', 'all', 'messed', 'up', 'going', 'nowhere', 'fast', 'but', 'circles', 'in', 'my', 'mind', 'so', 'blind', 'who', 'are', 'these', 'voices', 'in', 'my', 'head', 'cant', 'go', 'on', 'like', 'this', 'living', 'like', 'the', 'dead', 'havent', 'slept', 'so', 'long', 'feeling', 'sad', 'dread', 'im', 'talking', 'to', 'myself', 'forgot', 'what', 'just', 'said', 'cause', 'im', 'all', 'messed', 'up', 'making', 'prefect', 'nonsense', 'drowning', 'in', 'my', 'doubt', 'too', 'well', 'cause', 'im', 'all', 'messed', 'up', 'going', 'nowhere', 'fast', 'but', 'circles', 'in', 'my', 'mind', 'so', 'blind', 'well', 'hold', 'my', 'only', 'enemy', 'as', 'closely', 'as', 'friend', 'and', 'sold', 'my', 'own', 'reality', 'to', 'further', 'my', 'descent', 'selfdestruction', 'taking', 'over', 'its', 'so', 'easy', 'to', 'pretend', 'introduction', 'to', 'this', 'nightmare', 'may', 'never', 'end', 'can', 'anyone', 'help', 'me', 'drag', 'my', 'heels', 'im', 'running', 'overtime', 'cant', 'hold', 'down', 'my', 'meals', 'my', 'mind', 'is', 'racing', 'by', 'staring', 'blankly', 'feels', 'like', 'pulling', 'out', 'my', 'teeth', 'while', 'this', 'engine', 'winds', 'cause', 'im', 'all', 'messed', 'up', 'making', 'prefect', 'nonsense', 'drowning', 'in', 'my', 'doubt', 'too', 'well', 'cause', 'im', 'all', 'messed', 'up', 'going', 'nowhere', 'fast', 'but', 'circles', 'in', 'my', 'mind', 'so', 'blind']\n"
     ]
    }
   ],
   "source": [
    "# Stemming with PorterStemmer in train_data\n",
    "tokens_train = word_tokenize(train_data['Lyrics'][1])\n",
    "print(tokens_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['another', 'day', 'wasted', 'out', 'of', 'time', 'cant', 'get', 'out', 'of', 'this', 'altered', 'state', 'of', 'mind', 'im', 'going', 'overboard', 'my', 'conscience', 'meet', 'decline', 'into', 'reality', 'know', 'this', 'cant', 'be', 'fine', 'cause', 'im', 'all', 'messed', 'up', 'making', 'prefect', 'nonsense', 'drowning', 'in', 'my', 'doubt', 'too', 'well', 'cause', 'im', 'all', 'messed', 'up', 'going', 'nowhere', 'fast', 'but', 'circle', 'in', 'my', 'mind', 'so', 'blind', 'who', 'are', 'these', 'voice', 'in', 'my', 'head', 'cant', 'go', 'on', 'like', 'this', 'living', 'like', 'the', 'dead', 'havent', 'slept', 'so', 'long', 'feeling', 'sad', 'dread', 'im', 'talking', 'to', 'myself', 'forgot', 'what', 'just', 'said', 'cause', 'im', 'all', 'messed', 'up', 'making', 'prefect', 'nonsense', 'drowning', 'in', 'my', 'doubt', 'too', 'well', 'cause', 'im', 'all', 'messed', 'up', 'going', 'nowhere', 'fast', 'but', 'circle', 'in', 'my', 'mind', 'so', 'blind', 'well', 'hold', 'my', 'only', 'enemy', 'a', 'closely', 'a', 'friend', 'and', 'sold', 'my', 'own', 'reality', 'to', 'further', 'my', 'descent', 'selfdestruction', 'taking', 'over', 'it', 'so', 'easy', 'to', 'pretend', 'introduction', 'to', 'this', 'nightmare', 'may', 'never', 'end', 'can', 'anyone', 'help', 'me', 'drag', 'my', 'heel', 'im', 'running', 'overtime', 'cant', 'hold', 'down', 'my', 'meal', 'my', 'mind', 'is', 'racing', 'by', 'staring', 'blankly', 'feel', 'like', 'pulling', 'out', 'my', 'teeth', 'while', 'this', 'engine', 'wind', 'cause', 'im', 'all', 'messed', 'up', 'making', 'prefect', 'nonsense', 'drowning', 'in', 'my', 'doubt', 'too', 'well', 'cause', 'im', 'all', 'messed', 'up', 'going', 'nowhere', 'fast', 'but', 'circle', 'in', 'my', 'mind', 'so', 'blind']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization with WordNetLemmatizer in train_data\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmas = [lemmatizer.lemmatize(t) for t in tokens_train]\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'we', 'can', 'pop', 'bottl', 'all', 'night', 'babi', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'ga', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'babi', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'anytim', 'you', 'want', 'to', 'pick', 'up', 'the', 'telephon', 'you', 'know', 'it', 'aint', 'nothin', 'to', 'drop', 'coupl', 'stack', 'on', 'you', 'want', 'you', 'could', 'get', 'it', 'my', 'dear', 'five', 'million', 'dollar', 'home', 'drop', 'bentley', 'swear', 'yeah', 'wantcho', 'bodi', 'need', 'yo', 'bodi', 'long', 'as', 'you', 'got', 'me', 'you', 'wont', 'need', 'nobodi', 'you', 'want', 'it', 'got', 'it', 'go', 'get', 'it', 'buy', 'it', 'tell', 'em', 'other', 'broke', 'brother', 'be', 'quiet', 'stack', 'on', 'deck', 'patron', 'on', 'ice', 'and', 'we', 'can', 'pop', 'bottl', 'all', 'night', 'babi', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'ga', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'babi', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'shawti', 'you', 'da', 'hottest', 'love', 'the', 'way', 'you', 'drop', 'it', 'brain', 'so', 'good', 'good', 'coulda', 'swore', 'you', 'went', 'to', 'colleg', 'hundr', 'deposit', 'vacat', 'hit', 'the', 'tropic', 'caus', 'errbodi', 'know', 'it', 'aint', 'trickin', 'if', 'ya', 'got', 'it', 'ya', 'need', 'to', 'never', 'ever', 'got', 'ta', 'go', 'to', 'yo', 'wallet', 'long', 'as', 'got', 'rubberband', 'bank', 'in', 'my', 'pocket', 'five', 'six', 'ride', 'with', 'rim', 'and', 'bodi', 'kit', 'ya', 'aint', 'got', 'ta', 'downgrad', 'you', 'can', 'get', 'what', 'get', 'my', 'chick', 'can', 'have', 'what', 'she', 'want', 'and', 'go', 'in', 'everi', 'store', 'for', 'ani', 'bag', 'she', 'want', 'and', 'know', 'she', 'aint', 'never', 'had', 'man', 'like', 'that', 'to', 'buy', 'ya', 'anyth', 'your', 'heart', 'desir', 'like', 'that', 'yeah', 'wantcho', 'bodi', 'need', 'yo', 'bodi', 'long', 'as', 'you', 'got', 'me', 'you', 'wont', 'need', 'nobodi', 'you', 'want', 'it', 'got', 'it', 'go', 'get', 'it', 'buy', 'it', 'tellem', 'other', 'broke', 'nigga', 'be', 'quiet', 'stack', 'on', 'deck', 'patron', 'on', 'ice', 'and', 'we', 'can', 'pop', 'bottl', 'all', 'night', 'babi', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatev', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'ga', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'babi', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'im', 'talkin', 'big', 'boy', 'ride', 'and', 'big', 'boy', 'ice', 'let', 'me', 'put', 'thi', 'big', 'boy', 'in', 'yo', 'life']\n"
     ]
    }
   ],
   "source": [
    "# Stemming with PorterStemmer in test_data\n",
    "porter = PorterStemmer()\n",
    "pStems = [porter.stem(t) for t in tokens_test]\n",
    "print(pStems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'we', 'can', 'pop', 'bottle', 'all', 'night', 'baby', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'gas', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'baby', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'anytime', 'you', 'want', 'to', 'pick', 'up', 'the', 'telephone', 'you', 'know', 'it', 'aint', 'nothin', 'to', 'drop', 'couple', 'stack', 'on', 'you', 'wanted', 'you', 'could', 'get', 'it', 'my', 'dear', 'five', 'million', 'dollar', 'home', 'drop', 'bentleys', 'swear', 'yeah', 'wantcho', 'body', 'need', 'yo', 'body', 'long', 'a', 'you', 'got', 'me', 'you', 'wont', 'need', 'nobody', 'you', 'want', 'it', 'got', 'it', 'go', 'get', 'it', 'buy', 'it', 'tell', 'em', 'other', 'broke', 'brother', 'be', 'quiet', 'stack', 'on', 'deck', 'patrone', 'on', 'ice', 'and', 'we', 'can', 'pop', 'bottle', 'all', 'night', 'baby', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'gas', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'baby', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'shawty', 'you', 'da', 'hottest', 'love', 'the', 'way', 'you', 'drop', 'it', 'brain', 'so', 'good', 'good', 'coulda', 'swore', 'you', 'went', 'to', 'college', 'hundred', 'deposit', 'vacation', 'hit', 'the', 'tropic', 'cause', 'errbody', 'know', 'it', 'aint', 'trickin', 'if', 'ya', 'got', 'it', 'ya', 'need', 'to', 'never', 'ever', 'got', 'ta', 'go', 'to', 'yo', 'wallet', 'long', 'a', 'got', 'rubberband', 'bank', 'in', 'my', 'pocket', 'five', 'six', 'ride', 'with', 'rim', 'and', 'body', 'kit', 'ya', 'aint', 'got', 'ta', 'downgrade', 'you', 'can', 'get', 'what', 'get', 'my', 'chick', 'can', 'have', 'what', 'she', 'want', 'and', 'go', 'in', 'every', 'store', 'for', 'any', 'bag', 'she', 'want', 'and', 'know', 'she', 'aint', 'never', 'had', 'man', 'like', 'that', 'to', 'buy', 'ya', 'anything', 'your', 'heart', 'desire', 'like', 'that', 'yeah', 'wantcho', 'body', 'need', 'yo', 'body', 'long', 'a', 'you', 'got', 'me', 'you', 'wont', 'need', 'nobody', 'you', 'want', 'it', 'got', 'it', 'go', 'get', 'it', 'buy', 'it', 'tellem', 'other', 'broke', 'nigga', 'be', 'quiet', 'stack', 'on', 'deck', 'patrone', 'on', 'ice', 'and', 'we', 'can', 'pop', 'bottle', 'all', 'night', 'baby', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'have', 'whatever', 'you', 'like', 'you', 'like', 'yeah', 'late', 'night', 'sex', 'so', 'wet', 'and', 'so', 'tight', 'ill', 'gas', 'up', 'the', 'jet', 'for', 'you', 'tonight', 'baby', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'said', 'you', 'can', 'go', 'where', 'ever', 'you', 'like', 'you', 'like', 'yeah', 'im', 'talkin', 'big', 'boy', 'ride', 'and', 'big', 'boy', 'ice', 'let', 'me', 'put', 'this', 'big', 'boy', 'in', 'yo', 'life']\n"
     ]
    }
   ],
   "source": [
    "# Lemmatization with WordNetLemmatizer in train_data\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmas = [lemmatizer.lemmatize(t) for t in tokens_test]\n",
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
